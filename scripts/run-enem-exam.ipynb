{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6866501,"sourceType":"datasetVersion","datasetId":3852317},{"sourceId":7130689,"sourceType":"datasetVersion","datasetId":3825773}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install bitsandbytes accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-06T21:22:37.940210Z","iopub.execute_input":"2023-12-06T21:22:37.940830Z","iopub.status.idle":"2023-12-06T21:22:54.998372Z","shell.execute_reply.started":"2023-12-06T21:22:37.940793Z","shell.execute_reply":"2023-12-06T21:22:54.997457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install transformers==4.35.0","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:22:55.000443Z","iopub.execute_input":"2023-12-06T21:22:55.000764Z","iopub.status.idle":"2023-12-06T21:23:17.392452Z","shell.execute_reply.started":"2023-12-06T21:22:55.000735Z","shell.execute_reply":"2023-12-06T21:23:17.391328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"llm_name = \"mistral\" #\"falcon\" # \"mistral\" # 'llama2' # mistral, llama1\nmodel_size = 7 # 7 13 # 13 # 7 # 13 # 30\n\nbits = 4 # 0 #16 #16  16 # 8 # 4\nif bits == 16:\n    load_in_4bit=False\n    load_in_8bit=False\nif bits == 8:\n    load_in_4bit=False\n    load_in_8bit=True\nif bits == 4:\n    load_in_4bit=True\n    load_in_8bit=False\nelse:\n    load_in_4bit=False\n    load_in_8bit=False  ","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:23:17.393859Z","iopub.execute_input":"2023-12-06T21:23:17.394159Z","iopub.status.idle":"2023-12-06T21:23:17.400189Z","shell.execute_reply.started":"2023-12-06T21:23:17.394130Z","shell.execute_reply":"2023-12-06T21:23:17.399225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nif llm_name == 'sabia':\n    # https://huggingface.co/maritaca-ai/sabia-7b\n    tokenizer = AutoTokenizer.from_pretrained(f\"maritaca-ai/sabia-{model_size}b\", load_in_4bit=load_in_4bit,load_in_8bit=load_in_8bit)\n    model = AutoModelForCausalLM.from_pretrained(f\"maritaca-ai/sabia-{model_size}b\")\n\nif llm_name == 'mistral':\n    # https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n    # https://mistral.ai/news/announcing-mistral-7b/\n    # https://www.youtube.com/watch?v=eovBbABk3hw\n    print('Loading mistral...')\n    if bits == 4:\n        model = AutoModelForCausalLM.from_pretrained(f\"mistralai/Mistral-{model_size}B-Instruct-v0.1\", load_in_4bit=load_in_4bit,load_in_8bit=load_in_8bit, bnb_4bit_compute_dtype=torch.float16)\n        tokenizer = AutoTokenizer.from_pretrained(f\"mistralai/Mistral-{model_size}B-Instruct-v0.1\")\n    else:\n        model = AutoModelForCausalLM.from_pretrained(f\"mistralai/Mistral-{model_size}B-Instruct-v0.1\", load_in_4bit=load_in_4bit,load_in_8bit=load_in_8bit)\n        tokenizer = AutoTokenizer.from_pretrained(f\"mistralai/Mistral-{model_size}B-Instruct-v0.1\")\n    \nelif llm_name == 'falcon':\n    # https://huggingface.co/tiiuae/falcon-7b-instruct\n    model = AutoModelForCausalLM.from_pretrained(f\"tiiuae/falcon-{model_size}b-instruct\", load_in_4bit=load_in_4bit,load_in_8bit=load_in_8bit )\n    tokenizer = AutoTokenizer.from_pretrained(f\"tiiuae/falcon-{model_size}b-instruct\")\nelif llm_name == 'flat':\n    model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n    tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\nelif llm_name == 'llama1':\n    from transformers import LlamaForCausalLM , LlamaTokenizer\n    token = \"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\"\n    tokenizer = LlamaTokenizer.from_pretrained(f\"meta-llama/Llama-1-{model_size}b-chat-hf\", token=token)\n    #tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n    model = LlamaForCausalLM.from_pretrained(f\"meta-llama/Llama-1-{model_size}b-chat-hf\", load_in_4bit=load_in_4bit, load_in_8bit=load_in_8bit, token=token)\nelse:\n    from transformers import LlamaForCausalLM , LlamaTokenizer\n    token = \"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\"\n    tokenizer = LlamaTokenizer.from_pretrained(f\"meta-llama/Llama-2-{model_size}b-chat-hf\", token=token)\n    #tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n    model = LlamaForCausalLM.from_pretrained(f\"meta-llama/Llama-2-{model_size}b-chat-hf\", load_in_4bit=load_in_4bit, load_in_8bit=load_in_8bit, token=token)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:23:17.402232Z","iopub.execute_input":"2023-12-06T21:23:17.402566Z","iopub.status.idle":"2023-12-06T21:25:48.422779Z","shell.execute_reply.started":"2023-12-06T21:23:17.402542Z","shell.execute_reply":"2023-12-06T21:25:48.421909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport re\nimport pandas as pd\nimport copy\n\nPROVA = \"CH\"\n# humanas\n# enem_data = pd.read_csv(\"/kaggle/input/enem-data/ENEM_2022_P1_CAD_09_DIA_1_LARANJA_LEDOR.csv\")\n# exatas\n\nif PROVA == 'CH':\n    enem_data = pd.read_csv(\"/kaggle/input/enem-data/ENEM_2022_CH_CO_PROVA_1062.csv\")    \n\nif PROVA == \"MT\":\n    enem_data = pd.read_csv(\"/kaggle/input/enem-data/ENEM_2022_MT_CO_PROVA_1082.csv\")\n    \nif PROVA == \"EASY\":\n    enem_data = pd.read_csv(\"/kaggle/input/enem-data/PROVA_FACIL_2022_MT_CO_PROVA_1082.csv\")    \n\n# TODO: criar o arquivo da prova já assim.\nenem_data['question_number'] = enem_data['question'].str.extract(r'(\\d+)')\n\n# First item starts at 1.\nenem_data.index += 1\n\nenem_data.replace(\"anulada\", \"X\", inplace=True)\n\n\nenem_data_original = copy.deepcopy(enem_data)\n\nenem_data","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.424103Z","iopub.execute_input":"2023-12-06T21:25:48.424427Z","iopub.status.idle":"2023-12-06T21:25:48.505801Z","shell.execute_reply.started":"2023-12-06T21:25:48.424400Z","shell.execute_reply":"2023-12-06T21:25:48.504922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.506962Z","iopub.execute_input":"2023-12-06T21:25:48.507306Z","iopub.status.idle":"2023-12-06T21:25:48.513764Z","shell.execute_reply.started":"2023-12-06T21:25:48.507269Z","shell.execute_reply":"2023-12-06T21:25:48.512855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\n\n\ndef shuffle_order(question, question_order):\n    shuffled_question = copy.deepcopy(question)\n    shuffled_to_original_map = dict()\n    original_to_shuffled_map = dict()\n    \n    shuffled_question['A'] = question[question_order[0]]\n    shuffled_question['B'] = question[question_order[1]]\n    shuffled_question['C'] = question[question_order[2]]\n    shuffled_question['D'] = question[question_order[3]]\n    shuffled_question['E'] = question[question_order[4]]\n    \n    shuffled_to_original_map['A'] = question_order[0]\n    shuffled_to_original_map['B'] = question_order[1]\n    shuffled_to_original_map['C'] = question_order[2]\n    shuffled_to_original_map['D'] = question_order[3]\n    shuffled_to_original_map['E'] = question_order[4]\n    shuffled_to_original_map['X'] = 'X'\n    shuffled_to_original_map[None] = 'X'\n\n    original_to_shuffled_map[question_order[0]] = 'A'\n    original_to_shuffled_map[question_order[1]] = 'B'\n    original_to_shuffled_map[question_order[2]] = 'C'\n    original_to_shuffled_map[question_order[3]] = 'D'\n    original_to_shuffled_map[question_order[4]] = 'E'\n    original_to_shuffled_map['X'] = 'X'\n    original_to_shuffled_map[None] = 'X'\n    \n    return shuffled_question, shuffled_to_original_map, original_to_shuffled_map\n\nquestion_test = dict()\nquestion_test[\"A\"] = \"A_answer\"\nquestion_test[\"B\"] = \"B_answer\"\nquestion_test[\"C\"] = \"C_answer\"\nquestion_test[\"D\"] = \"D_answer\"\nquestion_test[\"E\"] = \"E_answer\"\n\n# TEST\nquestion_shuffled_order, shuffled_to_original_map, original_to_shuffled_map = shuffle_order(question_test, \"BECDA\")\nassert question_shuffled_order[\"E\"] == \"A_answer\"\nassert shuffled_to_original_map[\"E\"] == \"A\"\nassert original_to_shuffled_map[\"E\"] == \"B\"","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.514977Z","iopub.execute_input":"2023-12-06T21:25:48.515264Z","iopub.status.idle":"2023-12-06T21:25:48.526616Z","shell.execute_reply.started":"2023-12-06T21:25:48.515240Z","shell.execute_reply":"2023-12-06T21:25:48.525878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef build_structure(body, structure_id):\n    if structure_id == 0:\n        return body\n    elif structure_id == 1:\n         sentences = result = re.split(r'\\.|\\?', body)\n    \n         # Add \"Statement:\" before the last sentence\n         if len(sentences) > 1:\n            sentences[-1] = \"\\nStatement: \" + sentences[-1]\n    \n         # Join the sentences back into a single string\n         result = \"Question:\\nHeader: \" + '. '.join(sentences) + \"\\nAlternatives:\\n\"\n    \n    return result\n\nprint(build_structure(\"This, this and this happened. What really happened is that\", structure_id=1))\nprint(build_structure(\"This, this and this happened? What really happened is that\", structure_id=1))","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.527752Z","iopub.execute_input":"2023-12-06T21:25:48.528034Z","iopub.status.idle":"2023-12-06T21:25:48.543486Z","shell.execute_reply.started":"2023-12-06T21:25:48.528009Z","shell.execute_reply":"2023-12-06T21:25:48.542707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\n\n# Ao escutar a notícia de que um filme...\ndef question_138(question, question_seq=0):\n    movie_value = 35 + 10 * question_seq\n        \n    question['body'] = question['body'].replace(\"1,35 bi\", f\"1,{movie_value} bi\") \n    question['A'] =  f\"1{movie_value} 000,00.\" \n    question['B'] = f\"1 {movie_value}0 000,00.\" \n    question['C'] = f\"1{movie_value // 10} {movie_value%10}00 000,00.\"\n    question['D'] = f\"1{movie_value} 000 000,00.\"\n    question['E'] = f\"1 {movie_value}0 000 000,00.\"\n                \n    return question                          \n\ndef build_question(question,  correct_answer_original_order, question_order = \"ABCDE\", question_seq = 0, valid_option_count=5):\n    #if question['question_number'] == 138:\n    #    new_question = question_138(copy.deepcopy(question), question_seq=question_seq)\n    #else:\n    new_question = copy.deepcopy(question)\n\n    total_valid = 5\n    for option in ['A', 'B', 'C', 'D', 'E']:\n         if option != correct_answer_original_order and total_valid != valid_option_count:\n              new_question[option] = 'O pato está nadando na lagoa.'\n              total_valid = total_valid - 1\n        \n    new_question, shuffled_to_original_map, original_to_shuffled_map = shuffle_order(new_question, question_order)\n    return new_question, shuffled_to_original_map, original_to_shuffled_map\n\ndef format_enem_prompt(question,few_shot_questions=[], prompt_id = 0, structure_id=0, answer_separator=\".\", sys=True):\n    prompt = '[INST] '\n    if sys:\n        if prompt_id == -1:\n            prompt += '<<SYS>>\\nChoose an alternative you are most sure IT IS INCORRECT.\\n<</SYS>>\\n\\n'\n        if prompt_id == 0:\n           prompt += '<<SYS>>\\nYou are a machine designed to answer multiple choice questions with the correct alternative among A,B,C,D or E. Answer only with the correct alternative.\\n<</SYS>>\\n\\n'\n        elif prompt_id == 1:\n           prompt += '<<SYS>>\\nVoce é uma máquina que responde questões de múltipla escolha com a alternativa correta entre A, B, C, D e E. Responda apenas com a alternativa correta.\\n<</SYS>>\\n\\n'\n        elif prompt_id == 2:\n           prompt += '<<SYS>>\\nResponda à seguinte questão de múltipla escolha. \\n<</SYS>>\\n\\n'\n        elif prompt_id == 3:\n           prompt += '<<SYS>>\\nFormulate a chain of explanations that allows you to answer the multiple-choice question below. Only one alternative correct. Desired format: point out the alternatives that make sense, choose the CORRECT alternative and justify it, and finish justifying why the other alternatives are incorrect. Finish the explanation with “Answer:” followed by the alternative.\\n<</SYS>>\\n\\n'\n        elif prompt_id == 4:\n           prompt += '<<SYS>>\\nYou are a machine designed to answer multiple choice questions with the correct alternative among A,B, or C. Never choose D or E.\\n<</SYS>>\\n\\n'\n   \n        \n    body = build_structure(question['body'], structure_id)\n        \n    for few_shot in few_shot_questions:\n        #ignore few_shot if it is the same question\n        if few_shot['question'] == question['question']:\n            continue\n        prompt+= f'{few_shot[\"body\"]}\\n\\nA. {few_shot[\"A\"]}\\nB. {few_shot[\"B\"]}\\nC. {few_shot[\"C\"]}\\nD. {few_shot[\"D\"]}\\nE. {few_shot[\"E\"]}\\n[/INST]\\n'\n        prompt+= f'{few_shot[\"answer\"]}. {few_shot[few_shot[\"answer\"]]}\\n'\n        prompt+= '[INST]\\n'\n    #prompt += f'{body}\\n\\n'\n    #for r in order:\n    #    prompt += f'{r}. {question[r]}\\n'\n    #prompt += \"\\n[/INST]\"    \n    \n    if answer_separator == \"DOT\":\n        answer_separator = \".\"\n    if answer_separator == \"CLOSE_PAR\":\n        answer_separator = \")\"\n    \n    prompt += f'{body}\\n\\nA{answer_separator} {question[\"A\"]}\\nB{answer_separator} {question[\"B\"]}\\nC{answer_separator} {question[\"C\"]}\\nD{answer_separator} {question[\"D\"]}\\nE{answer_separator} {question[\"E\"]}\\n[/INST]'\n    return prompt","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-06T21:25:48.544736Z","iopub.execute_input":"2023-12-06T21:25:48.545015Z","iopub.status.idle":"2023-12-06T21:25:48.559882Z","shell.execute_reply.started":"2023-12-06T21:25:48.544992Z","shell.execute_reply":"2023-12-06T21:25:48.558978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef parse_answer(answer, question=None):\n    pos_inst = answer.split('[/INST]')[-1]\n    ans = pos_inst.strip()\n\n    pattern = r'answer is ([A-E])'\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n    \n    pattern = r'answer is \\(([A-E])\\)'\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n    \n    pattern = r'Answer: ([ABCDE])'\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n    \n    pattern = r'A resposta correta é (\\w):'\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n    \n    pattern = r'[Tt]he answer is ([A-E])'\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n    \n    pattern = r'answer is \\(([A-E])\\)'\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n        \n    pattern = r'A resposta correta é (\\w) '\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n\n    pattern = r'A resposta certa é (\\w):'\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n    \n    pattern = r'option ([A-E])'\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n\n    if re.match(r\"^(A|B|C|D|E)$\", ans):\n       return ans, pos_inst.strip()    \n    \n    pattern = r'\\(([A-E])\\)'\n    match = re.search(pattern, ans)\n    if match:\n        return match.group(1), ans.strip()\n   \n    ans = re.search('[ABCDE]\\.',ans).group().rstrip('.') if re.search('[ABCDE]\\.',ans) else None\n    \n    if ans is None:\n          pos_inst = answer.split('[/INST]')[-1]\n          ans = pos_inst.strip()\n          ans = re.search('[ABCDE]\\)',ans).group().rstrip(')') if re.search('[ABCDE]\\)',ans) else None\n        \n    if ans is None and question is not None:\n        for option in ['A', 'B', 'C', 'D', 'E']:\n            if question[option] in pos_inst:\n                return option, pos_inst.strip()\n    \n    return ans, pos_inst.strip()\n\n    \nassert parse_answer(\"[/INST] E. cinquenta e dois sessenta e quatro avos\") == (\"E\", \"E. cinquenta e dois sessenta e quatro avos\")\nassert parse_answer(\"[/INST] C.\") == (\"C\",\"C.\")\nassert parse_answer(\"[/INST] A\") == (\"A\", \"A\")\nassert parse_answer(\"(E) [/INST] B.\") == (\"B\", \"B.\")\nassert parse_answer(\"[/INST] The answer is A: Explanation.\") == (\"A\",\"The answer is A: Explanation.\")\nassert parse_answer(\"[/INST] The correct answer is (D). Explanation.\") == (\"D\", \"The correct answer is (D). Explanation.\")\nassert parse_answer(\"[/INST] The correct answer is D. Explanation (T).\") == (\"D\", \"The correct answer is D. Explanation (T).\")\nassert parse_answer(\"[/INST] A resposta correta é C:\") == (\"C\", \"A resposta correta é C:\")\nassert parse_answer(\"[/INST] A resposta correta é D - explicação\") == (\"D\", \"A resposta correta é D - explicação\")\nassert parse_answer(\"[/INST] A resposta certa é A:\") == (\"A\", \"A resposta certa é A:\")\nassert parse_answer(\"[/INST] C)\") == (\"C\",\"C)\")\nassert parse_answer(\"[/INST] Explanation (T). Answer: E. 2\") == ('E', 'Explanation (T). Answer: E. 2')\nassert parse_answer(\"[/INST] PI (π) is an irrational number. Therefore, the answer is (A) 3.14159.\")  == ('A', 'PI (π) is an irrational number. Therefore, the answer is (A) 3.14159.')\nassert parse_answer(\"[/INST] Therefore, the answer is E: 900 portions.\") == ('E', 'Therefore, the answer is E: 900 portions.')\nassert parse_answer(\"[/INST] I would choose option A: cat\") == ('A', 'I would choose option A: cat')\nassert parse_answer(\"[/INST] Answer: The correct answer is (A) cat.\") == ('A', 'Answer: The correct answer is (A) cat.')\n\n\nquestion = dict()\nquestion['A'] = 'answer_provided_in_option_A'\nquestion['B'] = 'answer_provided_in_option_B'\nassert parse_answer(\"[/INST] The answer is answer_provided_in_option_B\", question) == ('B', 'The answer is answer_provided_in_option_B')\nassert parse_answer(\"[/INST] Answer: answer_provided_in_option_A\", question) == ('A', 'Answer: answer_provided_in_option_A') \n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.563318Z","iopub.execute_input":"2023-12-06T21:25:48.563583Z","iopub.status.idle":"2023-12-06T21:25:48.585381Z","shell.execute_reply.started":"2023-12-06T21:25:48.563560Z","shell.execute_reply":"2023-12-06T21:25:48.584583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def merge_all_responses(source_directory, target_directory):\n        # Initialize an empty list to store DataFrames\n    dataframes = []\n\n    print(\"MERGING FROM \", source_directory, \" TO \", target_directory)\n    \n    # Iterate over files in the directory\n    for filename in os.listdir(source_directory):\n        if filename.startswith('test_responses_') and filename.endswith('.csv') and PROVA in filename:\n            file_path = os.path.join(source_directory, filename)\n            # Read the CSV file into a DataFrame\n            df = pd.read_csv(file_path)\n            dataframes.append(df)\n\n    # Concatenate all DataFrames into a single DataFrame\n    merged_df = pd.concat(dataframes, ignore_index=True)\n    # Specify the output file for the merged DataFrame\n    output_file = f'{target_directory}/test_responses_llms_{PROVA}.csv'\n\n    # Write the merged DataFrame to a CSV file\n    merged_df.sort_values(by=['CTT_SCORE','VALID_OPTION_COUNT', 'ANSWER_ORDER', 'TRIAL'], ascending=[False, True, False, True]).to_csv(output_file, index=False)\n    return merged_df\n    \ndef zip_all(PROVA, experiment_count):\n    \n    # ZIP ALL FILES FOR EASY DOWNLOAD\n    import shutil\n    import os\n\n    import time\n    time.sleep(10)\n\n    # Define the source directory and its path\n    source_directory = \"/kaggle/working/\"\n    output_base_name = f\"files_{PROVA}_{llm_name}_bits_{bits}_count_{experiment_count}\"\n\n    print(f\"Saving {output_base_name}.zip...\")\n\n    # Filter files in the source directory with the \".csv\" extension\n    # LOGS\n    selected_log_files = [f for f in os.listdir(source_directory + \"/logs\") if f.endswith(\".csv\")]\n\n    # Create a temporary directory to hold the selected files\n    temp_directory = \"/path/to/temp_directory/logs\"\n    os.makedirs(temp_directory, exist_ok=True)\n\n    for file_name in selected_log_files:\n        source_path = os.path.join(source_directory + \"/logs\", file_name)\n        dest_path = os.path.join(temp_directory, file_name)\n        shutil.copy(source_path, dest_path)\n        \n    # Filter files in the source directory with the \".csv\" extension\n    # RESPONSES\n    selected_response_files = [f for f in os.listdir(source_directory + \"/responses\") if f.endswith(\".csv\")]\n\n    # Create a temporary directory to hold the selected files\n    temp_directory = \"/path/to/temp_directory/responses\"\n    os.makedirs(temp_directory, exist_ok=True)\n\n    all_responses_df = merge_all_responses(source_directory + \"/responses\", temp_directory)\n    \n    choice_original_order_df  = generate_histogram_df(all_responses_df, 'choice_original_order', normalize=True)\n    choice_original_order_df.to_csv(temp_directory + \"/choice_original_order.csv\")\n    \n    shuffled_original_order_df  = generate_histogram_df(all_responses_df, 'choice_shuffled_order', normalize=True)\n    shuffled_original_order_df.to_csv(temp_directory + \"/choice_shuffled_order.csv\")\n    \n    correct_df  = generate_histogram_df(all_responses_df, 'correct_percentage', normalize=True)\n    correct_df.to_csv(temp_directory + \"/correct_percentage.csv\")\n    \n    \n    #for file_name in selected_response_files:\n    #    source_path = os.path.join(source_directory + \"/responses\", file_name)\n    #    dest_path = os.path.join(temp_directory, file_name)\n    #    shutil.copy(source_path, dest_path)            \n\n    # Create the archive from the temporary directory\n    shutil.make_archive(output_base_name, \"zip\", \"/path/to/temp_directory/\")\n\n    # Clean up the temporary directory\n    shutil.rmtree(temp_directory)\n\n    print('FILE SAVED!')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.586627Z","iopub.execute_input":"2023-12-06T21:25:48.586939Z","iopub.status.idle":"2023-12-06T21:25:48.602015Z","shell.execute_reply.started":"2023-12-06T21:25:48.586907Z","shell.execute_reply":"2023-12-06T21:25:48.601038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nimport numpy as np\n\ndic_gab_co_prova = { \"BEEDAEABDDCEBDBAAAAACXCBCCCBCCDBDEECBDCABEECD\": 1082,\n                     \"CBECABBCDEACDCEDAAADBCDDAECBABAECBEBAEEDADEAB\": 1062,\n                    \"AAAAAAAAAAAA\": 999, \n                    \"AAAAAAAAAAAAAAAAAAAAA\": 999,\n                      \"AA\": 999}\n\ndef write_response_file(trial, log_filename, shuffled_order_llm_response_pattern, shuffled_order_correct_response_pattern, llm_response_pattern, correct_response_pattern, response_01_pattern, ctt_score, question_template_seq, prompt_id, structure_id, valid_option_count, answer_separator, answer_order, elapsed_times):\n\n    # Define the data for t11he record\n    record = {\n        \"TRIAL\": trial,\n        \"MODEL_NAME\": llm_name,\n        \"MODEL_SIZE\": model_size,\n        \"BITS\": bits,\n        \"TEMPERATURE\": temperature,\n        \"ANSWER_ORDER\": answer_order,\n        \"ANSWER_SEPARATOR\": answer_separator,\n        \"PROMPT_ID\": prompt_id,\n        \"STRUCTURE_ID\": structure_id,\n        \"QUESTION_TEMPLATE_SEQ\": question_template_seq,\n        \"VALID_OPTION_COUNT\": valid_option_count,\n        \"CO_PROVA\": dic_gab_co_prova[correct_response_pattern],\n        \"SHUFFLED_ORDER_TX_RESPOSTAS\": shuffled_order_llm_response_pattern,\n        \"SHUFFLED_ORDER_TX_GABARITO\": shuffled_order_correct_response_pattern,\n        \"TX_RESPOSTAS\": llm_response_pattern,\n        \"TX_GABARITO\": correct_response_pattern,\n        \"RESPONSE_PATTERN\": response_01_pattern,\n        \"CTT_SCORE\": ctt_score,\n        \"TOTAL_RUN_TIME_SEC\": sum(elapsed_times),\n        \"AVG_RUN_TIME_PER_ITEM_SEC\": np.mean(elapsed_times),\n        \"LOG_FILE\": log_filename\n    }\n\n    # Specify the name of the CSV file\n    csv_file = \"/kaggle/working/responses\" + \"/\" + log_filename.replace(\"log_\", \"test_responses_llm_\")\n\n    # Open the CSV file in write mode\n    with open(csv_file, mode='w', newline='') as file:\n        # Define the column names\n        fieldnames = [\"TRIAL\", \"MODEL_NAME\", \"MODEL_SIZE\", \"BITS\", \"TEMPERATURE\", \"PROMPT_ID\", \"STRUCTURE_ID\", \"VALID_OPTION_COUNT\", \"ANSWER_SEPARATOR\", \"ANSWER_ORDER\", \"QUESTION_TEMPLATE_SEQ\", \"CTT_SCORE\", \"CO_PROVA\", \"SHUFFLED_ORDER_TX_RESPOSTAS\", \"SHUFFLED_ORDER_TX_GABARITO\", \"TX_RESPOSTAS\", \"TX_GABARITO\", \"RESPONSE_PATTERN\", \"TOTAL_RUN_TIME_SEC\", \"AVG_RUN_TIME_PER_ITEM_SEC\", \"LOG_FILE\"]\n\n        # Create a CSV writer object with the specified column names\n        csv_writer = csv.DictWriter(file, fieldnames=fieldnames)\n\n        # Write the column headers\n        csv_writer.writeheader()\n\n        print(record)\n    \n        # Write the record to the CSV file\n        csv_writer.writerow(record)\n\n    print(f\"Record has been written to {csv_file}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.603548Z","iopub.execute_input":"2023-12-06T21:25:48.604005Z","iopub.status.idle":"2023-12-06T21:25:48.621367Z","shell.execute_reply.started":"2023-12-06T21:25:48.603972Z","shell.execute_reply":"2023-12-06T21:25:48.620533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport copy\nimport os\n\nfrom pathlib import Path\n\nlog_directory_path = Path(\"/kaggle/working/logs\")\n# Create the directory and parent directories if they don't exist\nif not log_directory_path.exists():\n    log_directory_path.mkdir(parents=True)\n    \nresponse_directory_path = Path(\"/kaggle/working/responses\")\n# Create the directory and parent directories if they don't exist\nif not response_directory_path.exists():\n    response_directory_path.mkdir(parents=True)\n\ndef run_enem(trial, PROVA, llm_name, model_size, temperature, answer_order, question_template_seq, prompt_id, structure_id, valid_option_count, answer_separator):\n\n    log_filename = f\"log_{PROVA}_enem_2022_{llm_name}_{trial}_{model_size}_{temperature}_{bits}_{answer_order}_{question_template_seq}_{prompt_id}_{structure_id}_{valid_option_count}_{answer_separator}.csv\"   \n\n    questions = enem_data_original.to_dict(orient='records')\n    few_shot_questions = enem_data_original.sample(n=0,random_state=1).to_dict(orient='records')\n\n    question_bodies = []\n    As = []\n    Bs = []\n    Cs = []\n    Ds = []\n    Es = []\n\n    llm_alternatives_original_order=[]\n    llm_alternatives_shuffled_order=[]\n    \n    correct_answers_original_order=[]\n    correct_answers_shuffled_order=[]\n    \n    full_answers=[]\n    short_answers=[]\n    elapsed_times=[]\n    \n\n    question_count = 0\n\n    ctt_score = 0\n\n    shuffled_order_llm_response_pattern = \"\"\n    shuffled_order_correct_response_pattern = \"\"\n    \n    llm_response_pattern = \"\"\n    correct_response_pattern = \"\"\n    response_01_pattern = \"\"\n\n    for question in questions:\n        start_time = time.time()\n    \n        question['question_number'] = int(question['question_number'])\n    \n        question_number = question['question_number']\n    \n        if question_number < 0:\n            full_answers.append(\"SKIPPED\")\n            short_answers.append(\"SKIPPED\")\n            \n            llm_alternatives_original_order.append(\"SKIPPED\")\n            llm_alternatives_shuffled_order.append(\"SKIPPED\")\n            correct_answers_original_order.append(\"SKIPPED\")\n            correct_answers_shuffled_rder.append(\"SKIPPED\")\n            \n            elapsed_times.append(\"SKIPPED\")\n            question_bodies.append(\"SKIPPED\")\n            \n            As.append(\"SKIPPED\")\n            Bs.append(\"SKIPPED\")\n            Cs.append(\"SKIPPED\")\n            Ds.append(\"SKIPPED\")\n            Es.append(\"SKIPPED\")\n        else:\n            \n            question_count += 1\n                        \n            correct_answer_original_order = question['answer']\n        \n            question_built, shuffled_to_original_map, original_to_shuffled_map  = build_question(question, correct_answer_original_order, question_order=answer_order, question_seq=question_template_seq, valid_option_count=valid_option_count)\n            question_bodies.append(question_built['body'])\n            As.append(question_built['A'])\n            Bs.append(question_built['B'])\n            Cs.append(question_built['C'])\n            Ds.append(question_built['D'])\n            Es.append(question_built['E'])\n            \n            prompt = format_enem_prompt(question_built, few_shot_questions, prompt_id=prompt_id, structure_id=structure_id, answer_separator=answer_separator)\n\n            print(question_built['question'], 'valid_option_count', valid_option_count, 'temperature', temperature, 'template', question_template_seq, 'order ', answer_order, 'prompt', prompt_id, 'structure', structure_id) \n            #print('question', question_built['body'][:500])\n            print(prompt)\n            \n              \n            inputs = tokenizer(prompt,return_tensors='pt').input_ids.to(device)\n    \n            outputs = model.generate(inputs, temperature=temperature, do_sample=True, top_p=5, max_new_tokens=5000)\n            # outputs = model(inputs)\n    \n            full_answer = tokenizer.batch_decode(outputs,skip_special_tokens=True)[0]\n            \n            llm_alternative_shuffled_order, short_answer = parse_answer(full_answer, question_built)\n            \n            if llm_alternative_shuffled_order not in ['A', 'B', 'C', 'D', 'E']:\n                print(\"INVALID ANSWER!\", full_answer)\n            \n            llm_alternative_original_order = shuffled_to_original_map[llm_alternative_shuffled_order]\n\n            llm_alternatives_shuffled_order.append(llm_alternative_shuffled_order)\n            llm_alternatives_original_order.append(llm_alternative_original_order)\n            \n            correct_answer_shuffled_order = original_to_shuffled_map[correct_answer_original_order]\n            \n            correct_answers_original_order.append(correct_answer_original_order)\n            correct_answers_shuffled_order.append(correct_answer_shuffled_order)\n    \n            print('correct answer (shuffled order)', correct_answer_shuffled_order, 'llm answer (shuffled order)', llm_alternative_shuffled_order)\n            print('correct answer (original order)', correct_answer_original_order, 'llm answer (original order)', llm_alternative_original_order)\n    \n            full_answers.append(full_answer)\n            short_answers.append(short_answer)\n        \n            if llm_alternative_original_order == correct_answer_original_order or correct_answer_original_order == \"X\":\n                ctt_score += 1\n                response_01_pattern += \"1\"\n            else:\n                ctt_score += 0\n                response_01_pattern += \"0\"\n            \n            if llm_alternative_shuffled_order == None:\n                print(\"WARNING: llm new alternative is None\")\n                llm_alternative = \"X\"\n                llm_alternative_original_order = \"X\"\n                llm_alternative_shuffled_order = \"X\"\n            \n            if llm_alternative_original_order == None:\n                print(\"WARNING: llm alternative is None\")\n                llm_alternative = \"X\"\n                llm_alternative_original_order = \"X\"\n                llm_alternative_shuffled_order = \"X\"\n                \n            \n            shuffled_order_llm_response_pattern += llm_alternative_shuffled_order\n            shuffled_order_correct_response_pattern += correct_answer_shuffled_order\n            llm_response_pattern += llm_alternative_original_order\n            correct_response_pattern += correct_answer_original_order\n    \n            end_time = time.time()\n            print(f\"Elapsed time: {end_time - start_time} seconds\\n\")\n            elapsed_times.append(end_time - start_time)\n            \n        \n    enem_data['body'] = question_bodies\n    enem_data['A'] = As\n    enem_data['B'] = Bs\n    enem_data['C'] = Cs\n    enem_data['D'] = Ds\n    enem_data['E'] = Es\n   \n    enem_data['correct_answer_shuffled_order']=correct_answers_shuffled_order\n    enem_data['llm_alternative_shuffled_order']=llm_alternatives_shuffled_order\n    \n    enem_data['correct_answer_original_order']=correct_answers_original_order\n    enem_data['llm_alternative_original_order']=llm_alternatives_original_order\n   \n    enem_data['full_answer']=full_answers\n    enem_data['short_answer']=short_answers\n    enem_data['elapsed_time']=elapsed_times\n\n    enem_data.to_csv(f'/kaggle/working/logs/{log_filename}',index=True)\n    \n    write_response_file(trial, log_filename, shuffled_order_llm_response_pattern, shuffled_order_correct_response_pattern, llm_response_pattern, correct_response_pattern, response_01_pattern, ctt_score, question_template_seq, prompt_id, structure_id, valid_option_count, answer_separator, answer_order, elapsed_times)\n    print(\"FINISHED! CTT SCORE\", ctt_score, \"TOTAL_QUESTIONS\", question_count)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.622597Z","iopub.execute_input":"2023-12-06T21:25:48.622912Z","iopub.status.idle":"2023-12-06T21:25:48.651776Z","shell.execute_reply.started":"2023-12-06T21:25:48.622888Z","shell.execute_reply":"2023-12-06T21:25:48.650828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom scipy.stats import entropy\n\ndef generate_histogram_df(responses_df, o, normalize=True):\n\n    histograms = {}\n\n    for index, item in responses_df.iterrows():\n        for item_id, choice_original_order in enumerate(item['TX_RESPOSTAS'], start=1):\n\n            shuffled_response_pattern = item['SHUFFLED_ORDER_TX_RESPOSTAS']\n            response_pattern = item['TX_RESPOSTAS']\n\n            shuffled_correct_response_pattern = item['SHUFFLED_ORDER_TX_GABARITO']\n            correct_response_pattern = item['TX_GABARITO']\n        \n            choice_shuffled_order = shuffled_response_pattern[item_id-1]\n            correct_shuffled_order = shuffled_correct_response_pattern[item_id-1]\n\n            choice_original_order = response_pattern[item_id-1]\n            correct_original_order = correct_response_pattern[item_id-1]\n        \n            correct = choice_shuffled_order == correct_shuffled_order\n\n               \n            # Update the histogram for the current position and letter\n            if item_id not in histograms:\n                histograms[item_id] = { }\n\n            if o == 'choice_original_order':\n                letter = choice_original_order\n                histograms[item_id][letter] = histograms[item_id].get(letter, 0) + 1\n            elif o == 'choice_shuffled_order':\n                letter = choice_shuffled_order\n                histograms[item_id][letter] = histograms[item_id].get(letter, 0) + 1\n            elif o == 'correct_percentage':\n                if choice_shuffled_order == correct_shuffled_order:\n                    column_name = 'CORRECT'\n                    histograms[item_id][column_name] = histograms[item_id].get(column_name, 0) + 1\n                else:\n                    column_name = 'WRONG'\n                    histograms[item_id][column_name] = histograms[item_id].get(column_name, 0) + 1    \n            \n            \n\n    # Convert the histograms to a DataFrame for better presentation\n    histogram_df = pd.DataFrame(histograms).sort_index()\n    histogram_df.fillna(0, inplace=True)\n    # Display the resulting histogram DataFrame\n    if normalize:\n        normalized_histogram_df = histogram_df/histogram_df.sum()\n        normalized_histogram_df = normalized_histogram_df.transpose()\n        normalized_histogram_df['entropy'] = normalized_histogram_df.apply(entropy, axis=1) # +  np.random.uniform(-0.001, 0.001, len(normalized_histogram_df['A']))\n        return normalized_histogram_df\n    else:\n        return histogram_df.transpose()\n\n\n     ","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.653060Z","iopub.execute_input":"2023-12-06T21:25:48.653360Z","iopub.status.idle":"2023-12-06T21:25:48.667887Z","shell.execute_reply.started":"2023-12-06T21:25:48.653327Z","shell.execute_reply":"2023-12-06T21:25:48.666967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom itertools import permutations\nimport random\n\n\nanswer_orders = [\"EDCBA\",\"ABCDE\", \"EABCD\", \"DCBEA\"]\ntemperatures = [0.001, 0.01, 0.1, 0.5, 0.99]\nprompts = [0,1,2]\nquestion_templates = [0]\n\nn_trials = 1\nanswer_separators = [\"DOT\"]\nstructures = [0]\nanswer_orders = [\"ABCDE\", \"BCDEA\", \"CDEAB\", \"DEABC\", \"EABCD\", \"\"]\ntemperatures = [0.001]\nprompts = [0]\nquestion_templates = [0]\nvalid_options_count = [5]\n\nanswer_orders = list(permutations(\"ABCDE\"))\n#answer_orders = [\"ABCDE\"]\n#answer_orders = random.sample(answer_orders, len(answer_orders))\n\nexperiment_count = 0\n\nfor trial in range(1, n_trials + 1):\n    for prompt_id in prompts:\n       for temperature in temperatures:\n            for answer_order in answer_orders:\n              for question_template_seq in question_templates:\n                for structure_id in structures:\n                  for answer_separator in answer_separators:  \n                    for valid_option_count in valid_options_count:\n                        run_enem(trial, PROVA, llm_name, model_size, temperature, ''.join(answer_order), question_template_seq, prompt_id, structure_id, valid_option_count, answer_separator)\n\n                        experiment_count += 1\n                    if experiment_count % 10 == 0:\n                        zip_all(PROVA, experiment_count)\nzip_all(PROVA, experiment_count)                        \nprint(f\"FINISHED RUNNING ALL {experiment_count} ENEM EXAMS\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T21:25:48.668947Z","iopub.execute_input":"2023-12-06T21:25:48.669197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zip_all(PROVA, 8)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}