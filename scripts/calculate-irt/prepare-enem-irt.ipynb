{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b511b067-ecb7-4a96-bad1-fb860605568e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2344823 entries, 2 to 3476102\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   CO_PROVA_CN      float64\n",
      " 1   CO_PROVA_CH      float64\n",
      " 2   CO_PROVA_LC      float64\n",
      " 3   CO_PROVA_MT      float64\n",
      " 4   NU_NOTA_CN       float64\n",
      " 5   NU_NOTA_CH       float64\n",
      " 6   NU_NOTA_LC       float64\n",
      " 7   NU_NOTA_MT       float64\n",
      " 8   TX_RESPOSTAS_CN  object \n",
      " 9   TX_RESPOSTAS_CH  object \n",
      " 10  TX_RESPOSTAS_LC  object \n",
      " 11  TX_RESPOSTAS_MT  object \n",
      " 12  TP_LINGUA        int64  \n",
      " 13  TX_GABARITO_CN   object \n",
      " 14  TX_GABARITO_CH   object \n",
      " 15  TX_GABARITO_LC   object \n",
      " 16  TX_GABARITO_MT   object \n",
      "dtypes: float64(8), int64(1), object(8)\n",
      "memory usage: 322.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#alunos_df = pd.read_csv(\"C:/Users/pedro/Downloads/TRI/microdados_enem_2022/DADOS/MICRODADOS_ENEM_2022.csv\", nrows= 6 * 1000 * 1000, sep=\";\",  encoding='latin')\n",
    "\n",
    "columns_to_read = ['TP_LINGUA', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH', 'TX_RESPOSTAS_MT', 'TX_RESPOSTAS_LC', 'TX_GABARITO_CN', 'TX_GABARITO_MT', 'TX_GABARITO_CH', 'TX_GABARITO_LC']\n",
    "\n",
    "year = 2022\n",
    "alunos_df = pd.read_csv(f\"../../data/raw-enem-exams/microdados_enem_{year}/DADOS/MICRODADOS_ENEM_{year}.csv\", usecols=columns_to_read, nrows= 6 * 1000 * 1000, sep=\";\",  encoding='latin')\n",
    "item_df_path = f\"../../data/raw-enem-exams/microdados_enem_{year}/DADOS/ITENS_PROVA_{year}.csv\"\n",
    "\n",
    "alunos_df.dropna(subset=['TX_GABARITO_CH', 'TX_GABARITO_MT', 'TX_GABARITO_CN', 'TX_GABARITO_LC'], inplace=True)\n",
    "\n",
    "alunos_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a0bc1e-810e-4472-a08b-d2ddf8b567ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_CTT(row, tipo_prova):\n",
    "  \n",
    "    student_responses =  [char for char in row['TX_RESPOSTAS_' + tipo_prova]] \n",
    "    correct_responses = [char for char in row['TX_GABARITO_' + tipo_prova]]\n",
    "\n",
    "    # Verifique se os vetores têm o mesmo comprimento\n",
    "    if tipo_prova == 'LC' and len(correct_responses) == 50:\n",
    "        # Skip Spanish exam.\n",
    "         correct_responses = correct_responses[5:]\n",
    "    if tipo_prova == 'LC' and len(student_responses) == 50:\n",
    "        # Skip Spanish exam.\n",
    "         student_responses = student_responses[5:]\n",
    "        \n",
    "    if len(student_responses) != len(correct_responses):\n",
    "        return \"Os vetores têm comprimentos diferentes\"\n",
    "    \n",
    "    # Inicialize a contagem de respostas corretas\n",
    "    correct_count = 0\n",
    "    \n",
    "    # Percorra os vetores e conte as respostas corretas\n",
    "    for i in range(len(student_responses)):\n",
    "        if student_responses[i] == correct_responses[i]:\n",
    "            correct_count += 1\n",
    "    \n",
    "    return correct_count\n",
    "\n",
    "# Exemplo de uso da função:\n",
    "#student_answers = \"AAAABCCC\"\n",
    "#correct_answers = \"AAAABBBB\"\n",
    "\n",
    "#num_correct = grade_CTT(student_answers, correct_answers)\n",
    "#print(\"Número de respostas corretas:\", num_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7c378d-05fb-4d09-9345-9141330f2936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_PROVA_CH\n",
       "1057.0    584266\n",
       "1055.0    576449\n",
       "1058.0    576412\n",
       "1056.0    575951\n",
       "1178.0      7479\n",
       "1177.0      7400\n",
       "1176.0      7346\n",
       "1175.0      7332\n",
       "1063.0       928\n",
       "1062.0       335\n",
       "1136.0       242\n",
       "1135.0       239\n",
       "1137.0       233\n",
       "1138.0       211\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alunos_df['CO_PROVA_CH'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f75b40c-f177-4330-987d-292f92ae24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_pattern(row, tipo_prova):\n",
    "\n",
    "    response_pattern = \"\"\n",
    "    student_responses =  [char for char in row['TX_RESPOSTAS_' + tipo_prova]] \n",
    "    correct_responses = [char for char in row['TX_GABARITO_' + tipo_prova]]\n",
    "   \n",
    "    # Verifique se os vetores têm o mesmo comprimento\n",
    "    if tipo_prova == 'LC' and len(correct_responses) == 50:\n",
    "        # Skip Spanish exam.\n",
    "         correct_responses = correct_responses[5:]\n",
    "    if tipo_prova == 'LC' and len(student_responses) == 50:\n",
    "        # Skip Spanish exam.\n",
    "         student_responses = student_responses[5:]\n",
    "        \n",
    "    if len(student_responses) != len(correct_responses):\n",
    "        raise Exception(f\"Os vetores têm comprimentos diferentes. Estudante respondeu {len(student_responses)} e o gabarito tem {len(correct_responses)}\")\n",
    "    \n",
    "    # Inicialize a contagem de respostas corretas\n",
    "    correct_count = 0\n",
    "    \n",
    "    # Percorra os vetores e conte as respostas corretas\n",
    "    for i in range(len(student_responses)):\n",
    "        if student_responses[i] == correct_responses[i]:\n",
    "            response_pattern += \"1\"\n",
    "        else:       \n",
    "            response_pattern += \"0\"\n",
    "    \n",
    "    return response_pattern\n",
    "\n",
    "# Exemplo de uso da função:\n",
    "#student_answers = \"AAAABCCC\"\n",
    "#correct_answers = \"AAAABBBB\"\n",
    "\n",
    "#num_correct = grade_CTT(student_answers, correct_answers)\n",
    "#print(\"Número de respostas corretas:\", num_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63aca833-cf38-425f-a2a6-37f01f76460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tx_gabarito(row, tipo_prova):\n",
    "\n",
    "    response_pattern = \"\"\n",
    "    student_responses =  [char for char in row['TX_RESPOSTAS_' + tipo_prova]] \n",
    "    correct_responses = [char for char in row['TX_GABARITO_' + tipo_prova]]\n",
    "   \n",
    "    # Verifique se os vetores têm o mesmo comprimento\n",
    "    if tipo_prova == 'LC' and len(correct_responses) == 50:\n",
    "        # Skip Spanish exam.\n",
    "         correct_responses = correct_responses[5:]\n",
    "    if tipo_prova == 'LC' and len(student_responses) == 50:\n",
    "        # Skip Spanish exam.\n",
    "         student_responses = student_responses[5:]\n",
    "        \n",
    "    if len(student_responses) != len(correct_responses):\n",
    "        raise Exception(f\"Os vetores têm comprimentos diferentes. Estudante respondeu {len(student_responses)} e o gabarito tem {len(correct_responses)}\")\n",
    "    \n",
    "    # Inicialize a contagem de respostas corretas\n",
    "    correct_count = 0\n",
    "    \n",
    "    # Percorra os vetores e conte as respostas corretas\n",
    "    for i in range(len(student_responses)):\n",
    "        if student_responses[i] == correct_responses[i]:\n",
    "            response_pattern += \"1\"\n",
    "        else:       \n",
    "            response_pattern += \"0\"\n",
    "    \n",
    "    return ''.join(correct_responses)\n",
    "\n",
    "\n",
    "def tx_respostas(row, tipo_prova):\n",
    "\n",
    "    response_pattern = \"\"\n",
    "    student_responses =  [char for char in row['TX_RESPOSTAS_' + tipo_prova]] \n",
    "    correct_responses = [char for char in row['TX_GABARITO_' + tipo_prova]]\n",
    "   \n",
    "    # Verifique se os vetores têm o mesmo comprimento\n",
    "    if tipo_prova == 'LC' and len(correct_responses) == 50:\n",
    "        # Skip Spanish exam.\n",
    "         correct_responses = correct_responses[5:]\n",
    "    if tipo_prova == 'LC' and len(student_responses) == 50:\n",
    "        # Skip Spanish exam.\n",
    "         student_responses = student_responses[5:]\n",
    "        \n",
    "    if len(student_responses) != len(correct_responses):\n",
    "        raise Exception(f\"Os vetores têm comprimentos diferentes. Estudante respondeu {len(student_responses)} e o gabarito tem {len(correct_responses)}\")\n",
    "    \n",
    "    # Inicialize a contagem de respostas corretas\n",
    "    correct_count = 0\n",
    "    \n",
    "    # Percorra os vetores e conte as respostas corretas\n",
    "    for i in range(len(student_responses)):\n",
    "        if student_responses[i] == correct_responses[i]:\n",
    "            response_pattern += \"1\"\n",
    "        else:       \n",
    "            response_pattern += \"0\"\n",
    "    \n",
    "    return ''.join(student_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac8150a-0680-444b-8053-e3118f31f144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing CTTs...\n",
      "CTTs computed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing CTTs...\")\n",
    "\n",
    "'''\n",
    "alunos_df['CTT_SCORE_CH'] = alunos_df.apply(grade_CTT, axis=1,  args=('CH',))\n",
    "alunos_df['RESPONSE_PATTERN_CH'] = alunos_df.apply(response_pattern, axis=1, args=('CH',))\n",
    "\n",
    "alunos_df['CTT_SCORE_MT'] = alunos_df.apply(grade_CTT, axis=1,  args=('MT',))\n",
    "alunos_df['RESPONSE_PATTERN_MT'] = alunos_df.apply(response_pattern, axis=1, args=('MT',))\n",
    "\n",
    "alunos_df['CTT_SCORE_CN'] = alunos_df.apply(grade_CTT, axis=1,  args=('CN',))\n",
    "alunos_df['RESPONSE_PATTERN_CN'] = alunos_df.apply(response_pattern, axis=1, args=('CN',))\n",
    "'''\n",
    "\n",
    "alunos_df['CTT_SCORE_LC'] = alunos_df.apply(grade_CTT, axis=1,  args=('LC',))\n",
    "alunos_df['RESPONSE_PATTERN_LC'] = alunos_df.apply(response_pattern, axis=1, args=('LC',))\n",
    "alunos_df['TX_GABARITO_LC'] = alunos_df.apply(tx_gabarito, axis=1, args=('LC',))\n",
    "alunos_df['TX_RESPOSTAS_LC'] = alunos_df.apply(tx_respostas, axis=1, args=('LC',))\n",
    "\n",
    "print(\"CTTs computed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1848b5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alunos_df['TP_LINGUA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac48770-e4ab-4417-8940-72f900100958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_PROVA_CN</th>\n",
       "      <th>CO_PROVA_CH</th>\n",
       "      <th>CO_PROVA_LC</th>\n",
       "      <th>CO_PROVA_MT</th>\n",
       "      <th>NU_NOTA_CN</th>\n",
       "      <th>NU_NOTA_CH</th>\n",
       "      <th>NU_NOTA_LC</th>\n",
       "      <th>NU_NOTA_MT</th>\n",
       "      <th>TX_RESPOSTAS_CN</th>\n",
       "      <th>TX_RESPOSTAS_CH</th>\n",
       "      <th>TX_RESPOSTAS_LC</th>\n",
       "      <th>TX_RESPOSTAS_MT</th>\n",
       "      <th>TP_LINGUA</th>\n",
       "      <th>TX_GABARITO_CN</th>\n",
       "      <th>TX_GABARITO_CH</th>\n",
       "      <th>TX_GABARITO_LC</th>\n",
       "      <th>TX_GABARITO_MT</th>\n",
       "      <th>CTT_SCORE_LC</th>\n",
       "      <th>RESPONSE_PATTERN_LC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1086.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>396.8</td>\n",
       "      <td>528.7</td>\n",
       "      <td>551.4</td>\n",
       "      <td>536.0</td>\n",
       "      <td>ABEACDCACEADBDBDBAEBCDCABBBEDCBEBDACDAAECEDAE</td>\n",
       "      <td>CEABADCEDEBAECBADABBCDBDAAEDCEDBABCACBEDAEDEA</td>\n",
       "      <td>CCBDBECEAECBDDECACCDBACECCBADBCAADACCCDDBCEDE</td>\n",
       "      <td>CABACCAEEAABEDCCCBBECCBAEBEBCCDBDBAEDEDABEAEB</td>\n",
       "      <td>0</td>\n",
       "      <td>EACDDEBEACCCDABCEECBBCCAEBEDABEADBADDCBDDAAEB</td>\n",
       "      <td>DEABEEDAEBAAECBECBABCDDAAADBCEDAEACDBBCDCBECA</td>\n",
       "      <td>EDCAAEAAACABBDBEBACCBEEECCBBDCAAADCCABEDBDECE</td>\n",
       "      <td>DBAAACEBEDAECCBECDEECBDCABECBEABDDCCDBDXCBAAC</td>\n",
       "      <td>19</td>\n",
       "      <td>000001001001010000101001111010011101000110101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1086.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>466.5</td>\n",
       "      <td>476.2</td>\n",
       "      <td>488.3</td>\n",
       "      <td>462.7</td>\n",
       "      <td>CCDDCEEABDDDCABEDBEABCCBBCCEEDDEBCBCBDEBEECDB</td>\n",
       "      <td>BEADADABEEABDBBDBEABCDCBBEEECCABDBEACDDDAEDCE</td>\n",
       "      <td>CCDDBEEDAEDBCDEBECCDDAEDBCEDCAABEDDCECADBACAE</td>\n",
       "      <td>CBDCABEDEBABBEDBAEABCDDBDEBAAECBEDDBBCADCCECA</td>\n",
       "      <td>0</td>\n",
       "      <td>EACDDEBEACCCDABCEECBBCCAEBEDABEADBADDCBDDAAEB</td>\n",
       "      <td>DEABEEDAEBAAECBECBABCDDAAADBCEDAEACDBBCDCBECA</td>\n",
       "      <td>EDCAAEAAACABBDBEBACCBEEECCBBDCAAADCCABEDBDECE</td>\n",
       "      <td>DBAAACEBEDAECCBECDEECBDCABECBEABDDCCDBDXCBAAC</td>\n",
       "      <td>13</td>\n",
       "      <td>000001001001010000100010010000100101000110001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1086.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>386.5</td>\n",
       "      <td>458.5</td>\n",
       "      <td>479.7</td>\n",
       "      <td>383.1</td>\n",
       "      <td>DEBCDCEBDEBACDCBADBCECBEBDECADBD*BCDAEDCEDBAD</td>\n",
       "      <td>CAEBEDDAEDADBCDBDAABDBEAEDACCBACBDCEBDEDCACDE</td>\n",
       "      <td>BCEBEBDEBAACDBEDEACDEAEEBECBDEBEADACACBCBDECD</td>\n",
       "      <td>ABDCDABDCDECEBACECDCBAEBCADBCEADDBECBACEBAECE</td>\n",
       "      <td>0</td>\n",
       "      <td>EACDDEBEACCCDABCEECBBCCAEBEDABEADBADDCBDDAAEB</td>\n",
       "      <td>DEABEEDAEBAAECBECBABCDDAAADBCEDAEACDBBCDCBECA</td>\n",
       "      <td>EDCAAEAAACABBDBEBACCBEEECCBBDCAAADCCABEDBDECE</td>\n",
       "      <td>DBAAACEBEDAECCBECDEECBDCABECBEABDDCCDBDXCBAAC</td>\n",
       "      <td>15</td>\n",
       "      <td>000000000010000001100011000110001101100011110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1086.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>414.6</td>\n",
       "      <td>518.2</td>\n",
       "      <td>596.5</td>\n",
       "      <td>573.4</td>\n",
       "      <td>EBCDAACABEABDCABDAECBADACDBAEDCEBBDEAEDAAEBDD</td>\n",
       "      <td>DCACEECAEBADECAACBBBBADCECDEACCADBBEBDABBEDCA</td>\n",
       "      <td>DCBDEEAEAAACCDBCBECDEEEECCBBDCEAEEBCADADBAEDE</td>\n",
       "      <td>AACCECBEEDDCDEBDADCCBEEBDCABBDABDCCEAEDBAEBCD</td>\n",
       "      <td>0</td>\n",
       "      <td>EACDDEBEACCCDABCEECBBCCAEBEDABEADBADDCBDDAAEB</td>\n",
       "      <td>DEABEEDAEBAAECBECBABCDDAAADBCEDAEACDBBCDCBECA</td>\n",
       "      <td>EDCAAEAAACABBDBEBACCBEEECCBBDCAAADCCABEDBDECE</td>\n",
       "      <td>DBAAACEBEDAECCBECDEECBDCABECBEABDDCCDBDXCBAAC</td>\n",
       "      <td>24</td>\n",
       "      <td>000001101010011010100111111111010001100110101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1087.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>505.2</td>\n",
       "      <td>438.6</td>\n",
       "      <td>615.3</td>\n",
       "      <td>AEBDECABEBBCCBDBBBBECDCCBEAEAEAEBADBBCDCCEDBC</td>\n",
       "      <td>DDEABCEEDBEAEEECEACEADECACEDADACDBAACAEACAADA</td>\n",
       "      <td>DEDEDDDDBDCADECEADDBEEDBBCEEBEEDDEBEEBCBBECEB</td>\n",
       "      <td>BBEDABEBDACDEBBCECEABECBCBCABCDCDBCBCDBCBBDAA</td>\n",
       "      <td>0</td>\n",
       "      <td>DDECDBEACCAEBEAEBBCCDDCBDDACBEACEABCEABEDADBA</td>\n",
       "      <td>ECBABCDDAAECBCBECAEBAEACDEEDABBCDDEABCEDAAADB</td>\n",
       "      <td>DCEAADDBCABEDCAAADCCECEEBABEEAAABDBCCCABEECBB</td>\n",
       "      <td>BEEDAEABDDCEBDBAAAAACXCBCCCBCCDBDEECBDCABEECD</td>\n",
       "      <td>14</td>\n",
       "      <td>100001100000100011001000100100000010000101101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CO_PROVA_CN  CO_PROVA_CH  CO_PROVA_LC  CO_PROVA_MT  NU_NOTA_CN  \\\n",
       "17       1086.0       1055.0       1065.0       1076.0       396.8   \n",
       "20       1086.0       1055.0       1065.0       1076.0       466.5   \n",
       "25       1086.0       1055.0       1065.0       1076.0       386.5   \n",
       "27       1086.0       1055.0       1065.0       1076.0       414.6   \n",
       "29       1087.0       1056.0       1066.0       1078.0       437.0   \n",
       "\n",
       "    NU_NOTA_CH  NU_NOTA_LC  NU_NOTA_MT  \\\n",
       "17       528.7       551.4       536.0   \n",
       "20       476.2       488.3       462.7   \n",
       "25       458.5       479.7       383.1   \n",
       "27       518.2       596.5       573.4   \n",
       "29       505.2       438.6       615.3   \n",
       "\n",
       "                                  TX_RESPOSTAS_CN  \\\n",
       "17  ABEACDCACEADBDBDBAEBCDCABBBEDCBEBDACDAAECEDAE   \n",
       "20  CCDDCEEABDDDCABEDBEABCCBBCCEEDDEBCBCBDEBEECDB   \n",
       "25  DEBCDCEBDEBACDCBADBCECBEBDECADBD*BCDAEDCEDBAD   \n",
       "27  EBCDAACABEABDCABDAECBADACDBAEDCEBBDEAEDAAEBDD   \n",
       "29  AEBDECABEBBCCBDBBBBECDCCBEAEAEAEBADBBCDCCEDBC   \n",
       "\n",
       "                                  TX_RESPOSTAS_CH  \\\n",
       "17  CEABADCEDEBAECBADABBCDBDAAEDCEDBABCACBEDAEDEA   \n",
       "20  BEADADABEEABDBBDBEABCDCBBEEECCABDBEACDDDAEDCE   \n",
       "25  CAEBEDDAEDADBCDBDAABDBEAEDACCBACBDCEBDEDCACDE   \n",
       "27  DCACEECAEBADECAACBBBBADCECDEACCADBBEBDABBEDCA   \n",
       "29  DDEABCEEDBEAEEECEACEADECACEDADACDBAACAEACAADA   \n",
       "\n",
       "                                  TX_RESPOSTAS_LC  \\\n",
       "17  CCBDBECEAECBDDECACCDBACECCBADBCAADACCCDDBCEDE   \n",
       "20  CCDDBEEDAEDBCDEBECCDDAEDBCEDCAABEDDCECADBACAE   \n",
       "25  BCEBEBDEBAACDBEDEACDEAEEBECBDEBEADACACBCBDECD   \n",
       "27  DCBDEEAEAAACCDBCBECDEEEECCBBDCEAEEBCADADBAEDE   \n",
       "29  DEDEDDDDBDCADECEADDBEEDBBCEEBEEDDEBEEBCBBECEB   \n",
       "\n",
       "                                  TX_RESPOSTAS_MT  TP_LINGUA  \\\n",
       "17  CABACCAEEAABEDCCCBBECCBAEBEBCCDBDBAEDEDABEAEB          0   \n",
       "20  CBDCABEDEBABBEDBAEABCDDBDEBAAECBEDDBBCADCCECA          0   \n",
       "25  ABDCDABDCDECEBACECDCBAEBCADBCEADDBECBACEBAECE          0   \n",
       "27  AACCECBEEDDCDEBDADCCBEEBDCABBDABDCCEAEDBAEBCD          0   \n",
       "29  BBEDABEBDACDEBBCECEABECBCBCABCDCDBCBCDBCBBDAA          0   \n",
       "\n",
       "                                   TX_GABARITO_CN  \\\n",
       "17  EACDDEBEACCCDABCEECBBCCAEBEDABEADBADDCBDDAAEB   \n",
       "20  EACDDEBEACCCDABCEECBBCCAEBEDABEADBADDCBDDAAEB   \n",
       "25  EACDDEBEACCCDABCEECBBCCAEBEDABEADBADDCBDDAAEB   \n",
       "27  EACDDEBEACCCDABCEECBBCCAEBEDABEADBADDCBDDAAEB   \n",
       "29  DDECDBEACCAEBEAEBBCCDDCBDDACBEACEABCEABEDADBA   \n",
       "\n",
       "                                   TX_GABARITO_CH  \\\n",
       "17  DEABEEDAEBAAECBECBABCDDAAADBCEDAEACDBBCDCBECA   \n",
       "20  DEABEEDAEBAAECBECBABCDDAAADBCEDAEACDBBCDCBECA   \n",
       "25  DEABEEDAEBAAECBECBABCDDAAADBCEDAEACDBBCDCBECA   \n",
       "27  DEABEEDAEBAAECBECBABCDDAAADBCEDAEACDBBCDCBECA   \n",
       "29  ECBABCDDAAECBCBECAEBAEACDEEDABBCDDEABCEDAAADB   \n",
       "\n",
       "                                   TX_GABARITO_LC  \\\n",
       "17  EDCAAEAAACABBDBEBACCBEEECCBBDCAAADCCABEDBDECE   \n",
       "20  EDCAAEAAACABBDBEBACCBEEECCBBDCAAADCCABEDBDECE   \n",
       "25  EDCAAEAAACABBDBEBACCBEEECCBBDCAAADCCABEDBDECE   \n",
       "27  EDCAAEAAACABBDBEBACCBEEECCBBDCAAADCCABEDBDECE   \n",
       "29  DCEAADDBCABEDCAAADCCECEEBABEEAAABDBCCCABEECBB   \n",
       "\n",
       "                                   TX_GABARITO_MT  CTT_SCORE_LC  \\\n",
       "17  DBAAACEBEDAECCBECDEECBDCABECBEABDDCCDBDXCBAAC            19   \n",
       "20  DBAAACEBEDAECCBECDEECBDCABECBEABDDCCDBDXCBAAC            13   \n",
       "25  DBAAACEBEDAECCBECDEECBDCABECBEABDDCCDBDXCBAAC            15   \n",
       "27  DBAAACEBEDAECCBECDEECBDCABECBEABDDCCDBDXCBAAC            24   \n",
       "29  BEEDAEABDDCEBDBAAAAACXCBCCCBCCDBDEECBDCABEECD            14   \n",
       "\n",
       "                              RESPONSE_PATTERN_LC  \n",
       "17  000001001001010000101001111010011101000110101  \n",
       "20  000001001001010000100010010000100101000110001  \n",
       "25  000000000010000001100011000110001101100011110  \n",
       "27  000001101010011010100111111111010001100110101  \n",
       "29  100001100000100011001000100100000010000101101  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MT\n",
    "'''\n",
    "alunos_df[['TX_RESPOSTAS_MT','TX_GABARITO_MT', 'NU_NOTA_MT', 'CTT_SCORE_MT', 'CO_PROVA_MT', 'RESPONSE_PATTERN_MT']] \\\n",
    " .sort_values(by='NU_NOTA_MT', ascending=False) \\\n",
    " .rename(columns={'TX_RESPOSTAS_MT': 'TX_RESPOSTAS', 'TX_GABARITO_MT': 'TX_GABARITO', 'NU_NOTA_MT': 'NU_NOTA', 'CTT_SCORE_MT': 'CTT_SCORE', 'CO_PROVA_MT': 'CO_PROVA',  'RESPONSE_PATTERN_MT': 'RESPONSE_PATTERN'}) \\\n",
    " .to_csv(f\"C:/Users/pedro/Downloads/TRI/test_responses_humans/test_responses_humans_MT_{year}.csv\")\n",
    "\n",
    "# CH\n",
    "alunos_df[['TX_RESPOSTAS_CH','TX_GABARITO_CH', 'NU_NOTA_CH', 'CTT_SCORE_CH', 'CO_PROVA_CH', 'RESPONSE_PATTERN_CH']] \\\n",
    " .sort_values(by='NU_NOTA_CH', ascending=False) \\\n",
    " .rename(columns={'TX_RESPOSTAS_CH': 'TX_RESPOSTAS', 'TX_GABARITO_CH': 'TX_GABARITO', 'NU_NOTA_CH': 'NU_NOTA', 'CTT_SCORE_CH': 'CTT_SCORE', 'CO_PROVA_CH': 'CO_PROVA',  'RESPONSE_PATTERN_CH': 'RESPONSE_PATTERN'}) \\\n",
    " .to_csv(f\"C:/Users/pedro/Downloads/TRI/test_responses_humans/test_responses_humans_CH_{year}.csv\")\n",
    "\n",
    "# CN\n",
    "alunos_df[['TX_RESPOSTAS_CN','TX_GABARITO_CN', 'NU_NOTA_CN', 'CTT_SCORE_CN', 'CO_PROVA_CN', 'RESPONSE_PATTERN_CN']] \\\n",
    " .sort_values(by='NU_NOTA_CN', ascending=False) \\\n",
    " .rename(columns={'TX_RESPOSTAS_CN': 'TX_RESPOSTAS', 'TX_GABARITO_CN': 'TX_GABARITO', 'NU_NOTA_CN': 'NU_NOTA', 'CTT_SCORE_CN': 'CTT_SCORE', 'CO_PROVA_CN': 'CO_PROVA',  'RESPONSE_PATTERN_CN': 'RESPONSE_PATTERN'}) \\\n",
    " .to_csv(f\"C:/Users/pedro/Downloads/TRI/test_responses_humans/test_responses_humans_CN_{year}.csv\")\n",
    "'''\n",
    "\n",
    "# LC\n",
    "# Keep only studes who chose the Spanish exam instead of English.\n",
    "alunos_df[alunos_df['TP_LINGUA'] == 0][['TX_RESPOSTAS_LC','TX_GABARITO_LC', 'NU_NOTA_LC', 'CTT_SCORE_LC', 'CO_PROVA_LC', 'RESPONSE_PATTERN_LC', 'TP_LINGUA']] \\\n",
    " .sort_values(by='NU_NOTA_LC', ascending=False) \\\n",
    " .rename(columns={'TX_RESPOSTAS_LC': 'TX_RESPOSTAS', 'TX_GABARITO_LC': 'TX_GABARITO', 'NU_NOTA_LC': 'NU_NOTA', 'CTT_SCORE_LC': 'CTT_SCORE', 'CO_PROVA_LC': 'CO_PROVA',  'RESPONSE_PATTERN_LC': 'RESPONSE_PATTERN'}) \\\n",
    " .to_csv(f\"../../data/enem-human-responses/test_responses_humans_LC_{year}.csv\")\n",
    "\n",
    "alunos_df[alunos_df['TP_LINGUA'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "544675b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_PROVA_CN                                                   1087.0\n",
       "CO_PROVA_CH                                                   1056.0\n",
       "CO_PROVA_LC                                                   1066.0\n",
       "CO_PROVA_MT                                                   1078.0\n",
       "NU_NOTA_CN                                                     421.1\n",
       "NU_NOTA_CH                                                     546.0\n",
       "NU_NOTA_LC                                                     498.8\n",
       "NU_NOTA_MT                                                     565.3\n",
       "TX_RESPOSTAS_CN        DCDCEBADDABEDBCBEAEACCDDECEEBECBECAAECDDDDBCE\n",
       "TX_RESPOSTAS_CH        DBDABCADADECACBDCCEDACCCECDDABDCEADABCBCBAEAB\n",
       "TX_RESPOSTAS_LC        ABEABADCCADCAAAACDADDCECBAAACADABDEBCBCAAACEB\n",
       "TX_RESPOSTAS_MT        BDEBACECBCAEBABEDBABDACBCABCDEDEADBAABCBEACCD\n",
       "TP_LINGUA                                                          1\n",
       "TX_GABARITO_CN         DDECDBEACCAEBEAEBBCCDDCBDDACBEACEABCEABEDADBA\n",
       "TX_GABARITO_CH         ECBABCDDAAECBCBECAEBAEACDEEDABBCDDEABCEDAAADB\n",
       "TX_GABARITO_LC         DCEAADDBCABEDCAAADCCECEEBABEEAAABDBCCCABEECBB\n",
       "TX_GABARITO_MT         BEEDAEABDDCEBDBAAAAACXCBCCCBCCDBDEECBDCABEECD\n",
       "CTT_SCORE_LC                                                      19\n",
       "RESPONSE_PATTERN_LC    001100101100001101000110110001011100100000101\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alunos_df.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce204321-9ac5-437e-8f6c-e4585c4901c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "from collections import defaultdict\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "def generate_human_histogram_df(responses_df, PROVA, CO_PROVA, o, min_nota, max_nota):\n",
    "\n",
    "    #responses_df = responses_df[responses_df['CO_PROVA_'+PROVA] == CO_PROVA]\n",
    "   \n",
    "    itens_df = pd.read_csv(item_df_path, sep=';', encoding = \"latin\")\n",
    "    itens_df = itens_df[itens_df['SG_AREA'] == PROVA]\n",
    "    itens_df = itens_df[itens_df['TP_LINGUA'] != 0]\n",
    "    print('len_itens_df', len(itens_df))\n",
    "    \n",
    "    itens_df = itens_df.sort_values(by=['CO_PROVA','CO_POSICAO'], ascending=True) \n",
    "    \n",
    "    map_co_item_to_target_item_id = dict()\n",
    "    target_item_id = 0\n",
    "    for idx, item in itens_df.iterrows():\n",
    "        co_item = item['CO_ITEM']\n",
    "        co_posicao = item['CO_POSICAO']\n",
    "        co_prova = item['CO_PROVA']\n",
    "        gabarito = item['TX_GABARITO']\n",
    "\n",
    "        if co_prova == CO_PROVA:\n",
    "            target_item_id += 1\n",
    "            map_co_item_to_target_item_id[co_item] = target_item_id\n",
    "\n",
    "\n",
    "        #if co_item == 111664 and co_prova:\n",
    "        #    print('co_item', co_item, 'co_posicao', co_posicao, 'co_prova', co_prova, 'gabarito', gabarito, 'target_item_id', target_item_id)\n",
    "    \n",
    "    #print('map_co_item_to_target_item_id', map_co_item_to_target_item_id)\n",
    "    \n",
    "    map_co_prova_co_item_to_target_prova_item_id = defaultdict(dict)\n",
    "    map_co_prova_item_id_to_co_item = defaultdict(dict)\n",
    "    dic_item_id_count = defaultdict(int)\n",
    "    for idx, item in itens_df.iterrows():\n",
    "        co_item = item['CO_ITEM']\n",
    "        co_posicao = item['CO_POSICAO']\n",
    "        co_prova = item['CO_PROVA']\n",
    "        gabarito = item['TX_GABARITO']\n",
    "\n",
    "        dic_item_id_count[co_prova] += 1\n",
    "\n",
    "        if co_item not in map_co_item_to_target_item_id:\n",
    "            #print('co_item', co_item, 'not found in map_co_item_to_target_item_id')\n",
    "            continue\n",
    "\n",
    "        #print(co_prova, 'co_posicao', co_posicao, 'item_id', dic_item_id_count[co_prova], gabarito)\n",
    "        \n",
    "        #if co_item == 111664:\n",
    "        #    print('co_item', co_item, 'co_posicao', co_posicao, 'co_prova', co_prova, 'gabarito', gabarito, 'dic_item_id_count[co_prova]', dic_item_id_count[co_prova])\n",
    "        \n",
    "        map_co_prova_item_id_to_co_item[co_prova][dic_item_id_count[co_prova]]=co_item\n",
    "        map_co_prova_co_item_to_target_prova_item_id[co_prova][co_item] = map_co_item_to_target_item_id[co_item]\n",
    "\n",
    "        #print('co_prova', co_prova, 'co_posicao', co_posicao, 'item', dic_item_id_count[co_prova], 'is',co_item)\n",
    "\n",
    "    #print('map_co_prova_item_id_to_co_item contains PROVAS', map_co_prova_item_id_to_co_item.keys())\n",
    "    #for co_prova in map_co_prova_item_id_to_co_item.keys():\n",
    "        #print('prova ', co_prova, 'contains itens', map_co_prova_item_id_to_co_item[co_prova].keys())\n",
    "\n",
    "    # ACERTA ITENS_DF\n",
    "    itens_df = itens_df[itens_df['CO_PROVA'] == CO_PROVA].sort_values(by='CO_POSICAO', ascending=True)\n",
    "    itens_df.reset_index()\n",
    "    itens_df['human_item_id'] = range(1, len(itens_df) + 1)\n",
    "    \n",
    "    #print('len_responses_df', len(responses_df))\n",
    "    #print('map_co_prova_item_id_to_co_item', map_co_prova_item_id_to_co_item)\n",
    "    \n",
    "    options =  ['A', 'B', 'C', 'D', 'E']\n",
    "    \n",
    "    histograms_options = {}\n",
    "    histograms_correct = { }\n",
    "    correct_options = list()\n",
    "    correct_response_pattern = \"\"\n",
    "\n",
    "    student_count = 0\n",
    "\n",
    "    record_count = 0\n",
    "\n",
    "    filtered_responses_df = responses_df[(responses_df['NU_NOTA'] >= min_nota) & (responses_df['NU_NOTA'] <= max_nota)]\n",
    "    \n",
    "    dic_correct_option = dict()\n",
    "    for index, student in filtered_responses_df.iterrows():      \n",
    "        #if student['TP_PRESENCA_' + PROVA] != 1:\n",
    "        #    continue  \n",
    "    \n",
    "        co_prova = student['CO_PROVA']\n",
    "\n",
    "        if co_prova not in dic_item_id_count:\n",
    "            continue\n",
    "        \n",
    "        #if co_prova != CO_PROVA:\n",
    "        #    continue\n",
    "        \n",
    "        student_count += 1\n",
    "        #if student_count % 10000 == 0:\n",
    "       #     print('student_count', student_count)\n",
    "\n",
    "        #if student_count == 200000:\n",
    "        #    break\n",
    "\n",
    "        record_count += 1\n",
    "\n",
    "        for item_id, choice_original_order in enumerate(student['TX_RESPOSTAS'], start=1):\n",
    "            \n",
    "            #if co_prova != CO_PROVA:\n",
    "            #    continue\n",
    "            \n",
    "            #shuffled_response_pattern = item['SHUFFLED_ORDER_TX_RESPOSTAS']\n",
    "            response_pattern = student['TX_RESPOSTAS']\n",
    "            #shuffled_correct_response_pattern = item['SHUFFLED_ORDER_TX_GABARITO']\n",
    "            correct_response_pattern = student['TX_GABARITO']\n",
    "        \n",
    "            #choice_shuffled_order = shuffled_response_pattern[item_id-1]\n",
    "            #correct_shuffled_order = shuffled_correct_response_pattern[item_id-1]\n",
    "\n",
    "            choice_original_order = response_pattern[item_id-1]\n",
    "            correct_original_order = correct_response_pattern[item_id-1]\n",
    "\n",
    "            if item_id not in map_co_prova_item_id_to_co_item[co_prova]:\n",
    "                #print('item_id', item_id, 'not in co_prova', co_prova)\n",
    "                continue\n",
    "                \n",
    "            co_item = map_co_prova_item_id_to_co_item[co_prova][item_id]\n",
    "            target_item_id = map_co_prova_co_item_to_target_prova_item_id[co_prova][co_item]\n",
    "            correct = choice_original_order == correct_original_order\n",
    "\n",
    "            #if co_item == 111664:\n",
    "            #    print(\"Adding for co_prova\", co_prova, \"co_item\", co_item, \"item_id\", item_id, \"target_item_id\", target_item_id, \"correct\", correct_original_order)\n",
    "            #    print(\"AAAH! correct option for target_item_id \" + str(target_item_id) + \" differs. \" \\\n",
    "            #                    \"item_id is\",item_id, \\\n",
    "            #                    \"co_prova is\",co_prova,  \\\n",
    "            #                    \"gabarito is\", correct_response_pattern)\n",
    "            \n",
    "            if target_item_id in dic_correct_option and dic_correct_option[target_item_id] != correct_original_order:\n",
    "                raise Exception(\"Fatal error: correct option for target_item_id \" + str(target_item_id) + \" differs. \" \\\n",
    "                                \"item_id is\",item_id,\n",
    "                                \"co_prova is\",co_prova,  \\\n",
    "                                \"gabarito is\", correct_response_pattern, \\\n",
    "                                \"It is \" + dic_correct_option[target_item_id] + \"but we're trying to change to \" + correct_original_order)\n",
    "\n",
    "            dic_correct_option[target_item_id] = correct_original_order\n",
    "            \n",
    "            # Update the histogram for the current position and letter\n",
    "            if target_item_id not in histograms_options:\n",
    "                histograms_options[target_item_id] = { }\n",
    "                for option in options:\n",
    "                    histograms_options[target_item_id][option] = 0\n",
    "                histograms_correct[target_item_id] = { }\n",
    "\n",
    "                        \n",
    "            if o == 'choice_original_order':\n",
    "                letter = choice_original_order\n",
    "                if letter not in options:\n",
    "                    continue\n",
    "                histograms_options[target_item_id][letter] = histograms_options[target_item_id].get(letter, 0) + 1\n",
    "                          \n",
    "            elif o == 'choice_shuffled_order':\n",
    "                letter = choice_shuffled_order\n",
    "                histograms_options[target_item_id][letter] = histograms_options[target_item_id].get(letter, 0) + 1\n",
    "            \n",
    "            if choice_original_order == correct_original_order:\n",
    "                    column_name = 'human_accuracy'\n",
    "                    histograms_correct[target_item_id][column_name] = histograms_correct[target_item_id].get(column_name, 0) + 1\n",
    "            else:\n",
    "                    column_name = 'WRONG'\n",
    "                    histograms_correct[target_item_id][column_name] = histograms_correct[target_item_id].get(column_name, 0) + 1    \n",
    "\n",
    "    print('record_count', record_count)\n",
    "    #print('histogram_correct')\n",
    "    #for key in  sorted(histograms_correct.keys()):\n",
    "    #    print(f'{key}: {histograms_correct[key]}')\n",
    "\n",
    "    #print('dict_correct_option')\n",
    "    #for key in  sorted(dic_correct_option.keys()):\n",
    "    #    print(f'{key}: {dic_correct_option[key]}')\n",
    "\n",
    "\n",
    "    #print('histogram_options', histograms_options)\n",
    "    # Convert the histograms to a DataFrame for better presentation\n",
    "    histogram_options_df = pd.DataFrame(histograms_options).sort_index()\n",
    "    histogram_options_df.fillna(0, inplace=True)\n",
    "    histogram_options_df = histogram_options_df.sort_index(axis=1)\n",
    "\n",
    "    histogram_correct_df = pd.DataFrame(histograms_correct).sort_index()\n",
    "    histogram_correct_df.fillna(0, inplace=True)\n",
    "    histogram_correct_df = histogram_correct_df.sort_index(axis=1)\n",
    "\n",
    "    # Display the resulting histogram DataFrame\n",
    "    normalized_histogram_options_df = histogram_options_df/histogram_options_df.sum()\n",
    "    normalized_histogram_options_df = normalized_histogram_options_df.transpose()\n",
    "    normalized_histogram_options_df['human_entropy'] = normalized_histogram_options_df.apply(entropy, axis=1) # +  np.random.uniform(-0.001, 0.001, len(normalized_histogram_df['A']))  \n",
    "    normalized_histogram_options_df['human_item_id'] = range(1, len(normalized_histogram_options_df) + 1)\n",
    "\n",
    "    normalized_histogram_correct_df = histogram_correct_df/histogram_correct_df.sum()\n",
    "    normalized_histogram_correct_df = normalized_histogram_correct_df.transpose()\n",
    "    normalized_histogram_correct_df['human_item_id'] = range(1, len(normalized_histogram_correct_df) + 1)\n",
    "   \n",
    "    normalized_histogram_options_df['CORRECT_OPTION_HUMAN'] =  [value for key, value in sorted(dic_correct_option.items())]\n",
    "    histogram_df = pd.merge(normalized_histogram_options_df, normalized_histogram_correct_df, how='left', on='human_item_id')\n",
    "    return pd.merge(histogram_df, itens_df, how='left', on='human_item_id')\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5f0611-8582-4a0b-9038-3080ecde6232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading enem... (2022, 'LC', 1072)\n",
      "enem read.\n",
      "nota 0.0\n",
      "nota 447.9\n",
      "nota 501.9\n",
      "nota 548.5\n",
      "nota 776.3\n",
      "grouping...\n",
      "CO_PROVA\n",
      "1068.0    246758\n",
      "1067.0    242723\n",
      "1065.0    242370\n",
      "1066.0    242063\n",
      "1182.0      3177\n",
      "1181.0      3065\n",
      "1179.0      3058\n",
      "1180.0      3001\n",
      "1073.0       441\n",
      "1072.0       223\n",
      "1146.0        92\n",
      "1145.0        81\n",
      "1148.0        78\n",
      "1147.0        71\n",
      "Name: NU_NOTA, dtype: int64\n",
      "0.0 447.9\n",
      "len_itens_df 1305\n",
      "record_count 247103\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2022/itens/intermediarios/human_itens_LC_1072_2022_0_25.csv Index(['human_A_0_25', 'human_B_0_25', 'human_C_0_25', 'human_D_0_25',\n",
      "       'human_E_0_25', 'human_entropy_0_25', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_0_25', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "447.9 501.9\n",
      "len_itens_df 1305\n",
      "record_count 246859\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2022/itens/intermediarios/human_itens_LC_1072_2022_25_50.csv Index(['human_A_25_50', 'human_B_25_50', 'human_C_25_50', 'human_D_25_50',\n",
      "       'human_E_25_50', 'human_entropy_25_50', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_25_50', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "501.9 548.5\n",
      "len_itens_df 1305\n",
      "record_count 247707\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2022/itens/intermediarios/human_itens_LC_1072_2022_50_75.csv Index(['human_A_50_75', 'human_B_50_75', 'human_C_50_75', 'human_D_50_75',\n",
      "       'human_E_50_75', 'human_entropy_50_75', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_50_75', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "548.5 776.3\n",
      "len_itens_df 1305\n",
      "record_count 246900\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2022/itens/intermediarios/human_itens_LC_1072_2022_75_100.csv Index(['human_A_75_100', 'human_B_75_100', 'human_C_75_100', 'human_D_75_100',\n",
      "       'human_E_75_100', 'human_entropy_75_100', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_75_100', 'CO_POSICAO',\n",
      "       'SG_AREA', 'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "previous columns ['CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_ITEM', 'CO_ITEM', 'CO_ITEM', 'CO_ITEM', 'CO_POSICAO', 'CO_POSICAO', 'CO_POSICAO', 'CO_POSICAO', 'CO_PROVA', 'CO_PROVA', 'CO_PROVA', 'CO_PROVA', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_C', 'NU_PARAM_C', 'NU_PARAM_C', 'NU_PARAM_C', 'SG_AREA', 'SG_AREA', 'SG_AREA', 'SG_AREA', 'TP_LINGUA', 'TP_LINGUA', 'TP_LINGUA', 'TP_LINGUA', 'TX_COR', 'TX_COR', 'TX_COR', 'TX_COR', 'TX_GABARITO', 'TX_GABARITO', 'TX_GABARITO', 'TX_GABARITO', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'human_A_0_25', 'human_A_25_50', 'human_A_50_75', 'human_A_75_100', 'human_B_0_25', 'human_B_25_50', 'human_B_50_75', 'human_B_75_100', 'human_C_0_25', 'human_C_25_50', 'human_C_50_75', 'human_C_75_100', 'human_D_0_25', 'human_D_25_50', 'human_D_50_75', 'human_D_75_100', 'human_E_0_25', 'human_E_25_50', 'human_E_50_75', 'human_E_75_100', 'human_accuracy_0_25', 'human_accuracy_25_50', 'human_accuracy_50_75', 'human_accuracy_75_100', 'human_entropy_0_25', 'human_entropy_25_50', 'human_entropy_50_75', 'human_entropy_75_100', 'human_item_id', 'human_item_id', 'human_item_id', 'human_item_id']\n",
      "final columns ['CO_HABILIDADE', 'CO_ITEM', 'CO_POSICAO', 'CO_PROVA', 'IN_ITEM_ABAN', 'IN_ITEM_ADAPTADO', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'SG_AREA', 'TP_LINGUA', 'TX_COR', 'TX_GABARITO', 'TX_MOTIVO_ABAN', 'human_A_0_25', 'human_A_25_50', 'human_A_50_75', 'human_A_75_100', 'human_B_0_25', 'human_B_25_50', 'human_B_50_75', 'human_B_75_100', 'human_C_0_25', 'human_C_25_50', 'human_C_50_75', 'human_C_75_100', 'human_D_0_25', 'human_D_25_50', 'human_D_50_75', 'human_D_75_100', 'human_E_0_25', 'human_E_25_50', 'human_E_50_75', 'human_E_75_100', 'human_accuracy_0_25', 'human_accuracy_25_50', 'human_accuracy_50_75', 'human_accuracy_75_100', 'human_entropy_0_25', 'human_entropy_25_50', 'human_entropy_50_75', 'human_entropy_75_100']\n",
      "reading enem... (2021, 'LC', 896)\n",
      "enem read.\n",
      "nota 0.0\n",
      "nota 427.2\n",
      "nota 481.3\n",
      "nota 530.8\n",
      "nota 820.5\n",
      "grouping...\n",
      "CO_PROVA\n",
      "890.0     229046\n",
      "889.0     225965\n",
      "892.0     225825\n",
      "891.0     225580\n",
      "1026.0      9813\n",
      "1027.0      9680\n",
      "1025.0      9631\n",
      "1028.0      9618\n",
      "1006.0      3476\n",
      "1005.0      3449\n",
      "1003.0      3420\n",
      "1004.0      3372\n",
      "897.0        440\n",
      "969.0        222\n",
      "896.0        214\n",
      "970.0        213\n",
      "972.0        204\n",
      "971.0        203\n",
      "Name: NU_NOTA, dtype: int64\n",
      "0.0 427.2\n",
      "len_itens_df 1305\n",
      "record_count 240297\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2021/itens/intermediarios/human_itens_LC_896_2021_0_25.csv Index(['human_A_0_25', 'human_B_0_25', 'human_C_0_25', 'human_D_0_25',\n",
      "       'human_E_0_25', 'human_entropy_0_25', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_0_25', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "427.2 481.3\n",
      "len_itens_df 1305\n",
      "record_count 240497\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2021/itens/intermediarios/human_itens_LC_896_2021_25_50.csv Index(['human_A_25_50', 'human_B_25_50', 'human_C_25_50', 'human_D_25_50',\n",
      "       'human_E_25_50', 'human_entropy_25_50', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_25_50', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "481.3 530.8\n",
      "len_itens_df 1305\n",
      "record_count 240374\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2021/itens/intermediarios/human_itens_LC_896_2021_50_75.csv Index(['human_A_50_75', 'human_B_50_75', 'human_C_50_75', 'human_D_50_75',\n",
      "       'human_E_50_75', 'human_entropy_50_75', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_50_75', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "530.8 820.5\n",
      "len_itens_df 1305\n",
      "record_count 240463\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2021/itens/intermediarios/human_itens_LC_896_2021_75_100.csv Index(['human_A_75_100', 'human_B_75_100', 'human_C_75_100', 'human_D_75_100',\n",
      "       'human_E_75_100', 'human_entropy_75_100', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_75_100', 'CO_POSICAO',\n",
      "       'SG_AREA', 'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "previous columns ['CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_ITEM', 'CO_ITEM', 'CO_ITEM', 'CO_ITEM', 'CO_POSICAO', 'CO_POSICAO', 'CO_POSICAO', 'CO_POSICAO', 'CO_PROVA', 'CO_PROVA', 'CO_PROVA', 'CO_PROVA', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_C', 'NU_PARAM_C', 'NU_PARAM_C', 'NU_PARAM_C', 'SG_AREA', 'SG_AREA', 'SG_AREA', 'SG_AREA', 'TP_LINGUA', 'TP_LINGUA', 'TP_LINGUA', 'TP_LINGUA', 'TX_COR', 'TX_COR', 'TX_COR', 'TX_COR', 'TX_GABARITO', 'TX_GABARITO', 'TX_GABARITO', 'TX_GABARITO', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'human_A_0_25', 'human_A_25_50', 'human_A_50_75', 'human_A_75_100', 'human_B_0_25', 'human_B_25_50', 'human_B_50_75', 'human_B_75_100', 'human_C_0_25', 'human_C_25_50', 'human_C_50_75', 'human_C_75_100', 'human_D_0_25', 'human_D_25_50', 'human_D_50_75', 'human_D_75_100', 'human_E_0_25', 'human_E_25_50', 'human_E_50_75', 'human_E_75_100', 'human_accuracy_0_25', 'human_accuracy_25_50', 'human_accuracy_50_75', 'human_accuracy_75_100', 'human_entropy_0_25', 'human_entropy_25_50', 'human_entropy_50_75', 'human_entropy_75_100', 'human_item_id', 'human_item_id', 'human_item_id', 'human_item_id']\n",
      "final columns ['CO_HABILIDADE', 'CO_ITEM', 'CO_POSICAO', 'CO_PROVA', 'IN_ITEM_ABAN', 'IN_ITEM_ADAPTADO', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'SG_AREA', 'TP_LINGUA', 'TX_COR', 'TX_GABARITO', 'TX_MOTIVO_ABAN', 'human_A_0_25', 'human_A_25_50', 'human_A_50_75', 'human_A_75_100', 'human_B_0_25', 'human_B_25_50', 'human_B_50_75', 'human_B_75_100', 'human_C_0_25', 'human_C_25_50', 'human_C_50_75', 'human_C_75_100', 'human_D_0_25', 'human_D_25_50', 'human_D_50_75', 'human_D_75_100', 'human_E_0_25', 'human_E_25_50', 'human_E_50_75', 'human_E_75_100', 'human_accuracy_0_25', 'human_accuracy_25_50', 'human_accuracy_50_75', 'human_accuracy_75_100', 'human_entropy_0_25', 'human_entropy_25_50', 'human_entropy_50_75', 'human_entropy_75_100']\n",
      "reading enem... (2020, 'LC', 584)\n",
      "enem read.\n",
      "nota 0.0\n",
      "nota 461.1\n",
      "nota 510.4\n",
      "nota 554.4\n",
      "nota 770.5\n",
      "grouping...\n",
      "CO_PROVA\n",
      "579.0    307928\n",
      "577.0    303909\n",
      "580.0    303901\n",
      "578.0    303625\n",
      "659.0      8027\n",
      "660.0      7921\n",
      "658.0      7871\n",
      "657.0      7841\n",
      "693.0      3169\n",
      "691.0      3109\n",
      "694.0      3049\n",
      "692.0      3027\n",
      "585.0       637\n",
      "584.0       265\n",
      "Name: NU_NOTA, dtype: int64\n",
      "0.0 461.1\n",
      "len_itens_df 1195\n",
      "record_count 316288\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2020/itens/intermediarios/human_itens_LC_584_2020_0_25.csv Index(['human_A_0_25', 'human_B_0_25', 'human_C_0_25', 'human_D_0_25',\n",
      "       'human_E_0_25', 'human_entropy_0_25', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_0_25', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO', 'TP_VERSAO_DIGITAL'],\n",
      "      dtype='object')\n",
      "461.1 510.4\n",
      "len_itens_df 1195\n",
      "record_count 316818\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2020/itens/intermediarios/human_itens_LC_584_2020_25_50.csv Index(['human_A_25_50', 'human_B_25_50', 'human_C_25_50', 'human_D_25_50',\n",
      "       'human_E_25_50', 'human_entropy_25_50', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_25_50', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO', 'TP_VERSAO_DIGITAL'],\n",
      "      dtype='object')\n",
      "510.4 554.4\n",
      "len_itens_df 1195\n",
      "record_count 316511\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2020/itens/intermediarios/human_itens_LC_584_2020_50_75.csv Index(['human_A_50_75', 'human_B_50_75', 'human_C_50_75', 'human_D_50_75',\n",
      "       'human_E_50_75', 'human_entropy_50_75', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_50_75', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO', 'TP_VERSAO_DIGITAL'],\n",
      "      dtype='object')\n",
      "554.4 770.5\n",
      "len_itens_df 1195\n",
      "record_count 316518\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2020/itens/intermediarios/human_itens_LC_584_2020_75_100.csv Index(['human_A_75_100', 'human_B_75_100', 'human_C_75_100', 'human_D_75_100',\n",
      "       'human_E_75_100', 'human_entropy_75_100', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_75_100', 'CO_POSICAO',\n",
      "       'SG_AREA', 'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO', 'TP_VERSAO_DIGITAL'],\n",
      "      dtype='object')\n",
      "previous columns ['CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_ITEM', 'CO_ITEM', 'CO_ITEM', 'CO_ITEM', 'CO_POSICAO', 'CO_POSICAO', 'CO_POSICAO', 'CO_POSICAO', 'CO_PROVA', 'CO_PROVA', 'CO_PROVA', 'CO_PROVA', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_C', 'NU_PARAM_C', 'NU_PARAM_C', 'NU_PARAM_C', 'SG_AREA', 'SG_AREA', 'SG_AREA', 'SG_AREA', 'TP_LINGUA', 'TP_LINGUA', 'TP_LINGUA', 'TP_LINGUA', 'TP_VERSAO_DIGITAL', 'TP_VERSAO_DIGITAL', 'TP_VERSAO_DIGITAL', 'TP_VERSAO_DIGITAL', 'TX_COR', 'TX_COR', 'TX_COR', 'TX_COR', 'TX_GABARITO', 'TX_GABARITO', 'TX_GABARITO', 'TX_GABARITO', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'human_A_0_25', 'human_A_25_50', 'human_A_50_75', 'human_A_75_100', 'human_B_0_25', 'human_B_25_50', 'human_B_50_75', 'human_B_75_100', 'human_C_0_25', 'human_C_25_50', 'human_C_50_75', 'human_C_75_100', 'human_D_0_25', 'human_D_25_50', 'human_D_50_75', 'human_D_75_100', 'human_E_0_25', 'human_E_25_50', 'human_E_50_75', 'human_E_75_100', 'human_accuracy_0_25', 'human_accuracy_25_50', 'human_accuracy_50_75', 'human_accuracy_75_100', 'human_entropy_0_25', 'human_entropy_25_50', 'human_entropy_50_75', 'human_entropy_75_100', 'human_item_id', 'human_item_id', 'human_item_id', 'human_item_id']\n",
      "final columns ['CO_HABILIDADE', 'CO_ITEM', 'CO_POSICAO', 'CO_PROVA', 'IN_ITEM_ABAN', 'IN_ITEM_ADAPTADO', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'SG_AREA', 'TP_LINGUA', 'TP_VERSAO_DIGITAL', 'TX_COR', 'TX_GABARITO', 'human_A_0_25', 'human_A_25_50', 'human_A_50_75', 'human_A_75_100', 'human_B_0_25', 'human_B_25_50', 'human_B_50_75', 'human_B_75_100', 'human_C_0_25', 'human_C_25_50', 'human_C_50_75', 'human_C_75_100', 'human_D_0_25', 'human_D_25_50', 'human_D_50_75', 'human_D_75_100', 'human_E_0_25', 'human_E_25_50', 'human_E_50_75', 'human_E_75_100', 'human_accuracy_0_25', 'human_accuracy_25_50', 'human_accuracy_50_75', 'human_accuracy_75_100', 'human_entropy_0_25', 'human_entropy_25_50', 'human_entropy_50_75', 'human_entropy_75_100']\n",
      "reading enem... (2019, 'LC', 521)\n",
      "enem read.\n",
      "nota 0.0\n",
      "nota 470.4\n",
      "nota 511.2\n",
      "nota 546.5\n",
      "nota 761.6\n",
      "grouping...\n",
      "CO_PROVA\n",
      "512.0    469225\n",
      "514.0    465327\n",
      "511.0    465036\n",
      "513.0    463561\n",
      "525.0      1138\n",
      "521.0       358\n",
      "Name: NU_NOTA, dtype: int64\n",
      "0.0 470.4\n",
      "len_itens_df 495\n",
      "record_count 466398\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2019/itens/intermediarios/human_itens_LC_521_2019_0_25.csv Index(['human_A_0_25', 'human_B_0_25', 'human_C_0_25', 'human_D_0_25',\n",
      "       'human_E_0_25', 'human_entropy_0_25', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_0_25', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "470.4 511.2\n",
      "len_itens_df 495\n",
      "record_count 467774\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2019/itens/intermediarios/human_itens_LC_521_2019_25_50.csv Index(['human_A_25_50', 'human_B_25_50', 'human_C_25_50', 'human_D_25_50',\n",
      "       'human_E_25_50', 'human_entropy_25_50', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_25_50', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "511.2 546.5\n",
      "len_itens_df 495\n",
      "record_count 467043\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2019/itens/intermediarios/human_itens_LC_521_2019_50_75.csv Index(['human_A_50_75', 'human_B_50_75', 'human_C_50_75', 'human_D_50_75',\n",
      "       'human_E_50_75', 'human_entropy_50_75', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_50_75', 'CO_POSICAO', 'SG_AREA',\n",
      "       'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "546.5 761.6\n",
      "len_itens_df 495\n",
      "record_count 466909\n",
      "SAVING C:/Users/pedro/Downloads/TRI/test_responses_humans/2019/itens/intermediarios/human_itens_LC_521_2019_75_100.csv Index(['human_A_75_100', 'human_B_75_100', 'human_C_75_100', 'human_D_75_100',\n",
      "       'human_E_75_100', 'human_entropy_75_100', 'human_item_id',\n",
      "       'CORRECT_OPTION_HUMAN', 'human_accuracy_75_100', 'CO_POSICAO',\n",
      "       'SG_AREA', 'CO_ITEM', 'TX_GABARITO', 'CO_HABILIDADE', 'IN_ITEM_ABAN',\n",
      "       'TX_MOTIVO_ABAN', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'TX_COR',\n",
      "       'CO_PROVA', 'TP_LINGUA', 'IN_ITEM_ADAPTADO'],\n",
      "      dtype='object')\n",
      "previous columns ['CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CORRECT_OPTION_HUMAN', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_HABILIDADE', 'CO_ITEM', 'CO_ITEM', 'CO_ITEM', 'CO_ITEM', 'CO_POSICAO', 'CO_POSICAO', 'CO_POSICAO', 'CO_POSICAO', 'CO_PROVA', 'CO_PROVA', 'CO_PROVA', 'CO_PROVA', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ABAN', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'IN_ITEM_ADAPTADO', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_B', 'NU_PARAM_C', 'NU_PARAM_C', 'NU_PARAM_C', 'NU_PARAM_C', 'SG_AREA', 'SG_AREA', 'SG_AREA', 'SG_AREA', 'TP_LINGUA', 'TP_LINGUA', 'TP_LINGUA', 'TP_LINGUA', 'TX_COR', 'TX_COR', 'TX_COR', 'TX_COR', 'TX_GABARITO', 'TX_GABARITO', 'TX_GABARITO', 'TX_GABARITO', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'TX_MOTIVO_ABAN', 'human_A_0_25', 'human_A_25_50', 'human_A_50_75', 'human_A_75_100', 'human_B_0_25', 'human_B_25_50', 'human_B_50_75', 'human_B_75_100', 'human_C_0_25', 'human_C_25_50', 'human_C_50_75', 'human_C_75_100', 'human_D_0_25', 'human_D_25_50', 'human_D_50_75', 'human_D_75_100', 'human_E_0_25', 'human_E_25_50', 'human_E_50_75', 'human_E_75_100', 'human_accuracy_0_25', 'human_accuracy_25_50', 'human_accuracy_50_75', 'human_accuracy_75_100', 'human_entropy_0_25', 'human_entropy_25_50', 'human_entropy_50_75', 'human_entropy_75_100', 'human_item_id', 'human_item_id', 'human_item_id', 'human_item_id']\n",
      "final columns ['CO_HABILIDADE', 'CO_ITEM', 'CO_POSICAO', 'CO_PROVA', 'IN_ITEM_ABAN', 'IN_ITEM_ADAPTADO', 'NU_PARAM_A', 'NU_PARAM_B', 'NU_PARAM_C', 'SG_AREA', 'TP_LINGUA', 'TX_COR', 'TX_GABARITO', 'TX_MOTIVO_ABAN', 'human_A_0_25', 'human_A_25_50', 'human_A_50_75', 'human_A_75_100', 'human_B_0_25', 'human_B_25_50', 'human_B_50_75', 'human_B_75_100', 'human_C_0_25', 'human_C_25_50', 'human_C_50_75', 'human_C_75_100', 'human_D_0_25', 'human_D_25_50', 'human_D_50_75', 'human_D_75_100', 'human_E_0_25', 'human_E_25_50', 'human_E_50_75', 'human_E_75_100', 'human_accuracy_0_25', 'human_accuracy_25_50', 'human_accuracy_50_75', 'human_accuracy_75_100', 'human_entropy_0_25', 'human_entropy_25_50', 'human_entropy_50_75', 'human_entropy_75_100']\n",
      "FINISHED.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 2022\n",
    "# CH 1062 \n",
    "# MT 1082\n",
    "# CN 1092\n",
    "\n",
    "# 2021\n",
    "# CH 886\n",
    "# CN 916\n",
    "# MT 906\n",
    "\n",
    "# 2020\n",
    "# CH 574\n",
    "# CN 604\n",
    "# MT 594\n",
    "\n",
    "# 2019\n",
    "# CH 520\n",
    "# MT 522\n",
    "# CN 519\n",
    "\n",
    "# 2018\n",
    "# CH 464\n",
    "# MT 466\n",
    "\n",
    "ch_tuples = [(2022, 'CH', 1062), (2021, 'CH', 886), (2020, 'CH', 574), (2019, 'CH', 520), (2018, 'CH', 464)]\n",
    "cn_tuples = [(2022, 'CN', 1092), (2021, 'CN', 916), (2020, 'CN', 604), (2019, 'CN', 519), (2018, 'CN', 463)]\n",
    "mt_tuples = [(2022, 'MT', 1082), (2021, 'MT', 906), (2020, 'MT', 594), (2019, 'MT', 522), (2018, 'MT', 466)]\n",
    "lc_tuples = [(2022, 'LC', 1072), (2021, 'LC', 896), (2020, 'LC', 584), (2019, 'LC', 521)]\n",
    "\n",
    "\n",
    "for tuple in lc_tuples:\n",
    "    print('reading enem...', tuple)\n",
    "    \n",
    "    year = tuple[0]\n",
    "    PROVA = tuple[1]\n",
    "    co_prova = tuple[2]\n",
    "    \n",
    "    columns = ['CO_PROVA_'+PROVA,'NU_NOTA_'+PROVA,'TX_RESPOSTAS_'+PROVA,'TX_GABARITO_'+PROVA, 'TP_PRESENCA_'+PROVA]\n",
    "\n",
    "    enem_human_df = pd.read_csv(f\"C:/Users/pedro/Downloads/TRI/test_responses_humans/{year}/responses/test_responses_humans_{PROVA}_{year}.csv\")\n",
    "    enem_human_df.sort_values(by='NU_NOTA', inplace=True, ascending=False)\n",
    "\n",
    "    #enem_human_df = pd.read_csv(f\"C:/Users/pedro/Downloads/TRI/microdados/microdados_enem_{year}/DADOS/MICRODADOS_ENEM_{year}.csv\", usecols=columns, sep=\";\",  encoding='latin') \n",
    "    item_df_path = f\"c:/Users/pedro/Downloads/TRI/microdados/microdados_enem_{year}/DADOS/ITENS_PROVA_{year}.csv\"\n",
    "\n",
    "    print('enem read.')\n",
    "    percentiles = [0, 0.25, 0.50, 0.75, 1.0]\n",
    "    str_percentiles = [0, 25, 50, 75, 100]\n",
    "    #percentiles = [0,1]\n",
    "    #percentiles = [0, 50, 100]\n",
    "    nota_percentis = []\n",
    "    percentil_idx = 0\n",
    "    for p in percentiles:\n",
    "        nota = enem_human_df['NU_NOTA'].quantile(p)\n",
    "        print('nota', nota)\n",
    "        nota_percentis.append(nota)\n",
    "\n",
    "    print('grouping...')\n",
    "    grouped = enem_human_df.groupby('CO_PROVA')['NU_NOTA'].count().sort_values(ascending=False)\n",
    "    print(grouped)\n",
    "\n",
    "    co_provas = enem_human_df['CO_PROVA'].unique()\n",
    "    enem_human_df.sort_values(by='NU_NOTA', inplace=True, ascending=False)\n",
    "\n",
    "    all_dfs = []\n",
    "    for id_percentil in range(0, len(nota_percentis) - 1):\n",
    "         min_nota = nota_percentis[id_percentil]\n",
    "         max_nota = nota_percentis[id_percentil+1]\n",
    "         string_pct = str(str_percentiles[id_percentil]) + \"_\" + str(str_percentiles[id_percentil+1])\n",
    "            \n",
    "         print(min_nota, max_nota)   \n",
    "         df = generate_human_histogram_df(enem_human_df, PROVA=PROVA, CO_PROVA=co_prova, o='choice_original_order', min_nota=min_nota,max_nota=max_nota)\n",
    "         df.rename(columns={'A': 'human_A_'+string_pct, 'B': 'human_B_'+string_pct, 'C': 'human_C_'+string_pct, 'D': 'human_D_'+string_pct, 'E': 'human_E_'+string_pct}, inplace=True)\n",
    "         df.rename(columns={'human_accuracy':'human_accuracy_'+string_pct},inplace=True)\n",
    "         df.rename(columns={'human_entropy':'human_entropy_'+string_pct},inplace=True)\n",
    "         if 'WRONG' in df.columns:\n",
    "               df.drop(columns='WRONG', inplace=True)\n",
    "         all_dfs.append(df)\n",
    "         filename = f\"C:/Users/pedro/Downloads/TRI/test_responses_humans/{year}/itens/intermediarios/human_itens_{PROVA}_{int(co_prova)}_{year}_{string_pct}.csv\"\n",
    "         print(\"SAVING\", filename, df.columns)\n",
    "         df.to_csv(filename)\n",
    "        \n",
    "    result_df = pd.concat(all_dfs, axis=1, verify_integrity=False)\n",
    "    print('previous columns',sorted(result_df.columns))\n",
    "    result_df = result_df.loc[:,~result_df.T.duplicated(keep='last')]\n",
    "    print('final columns', sorted(result_df.columns))\n",
    "    result_df.to_csv(f\"C:/Users/pedro/Downloads/TRI/test_responses_humans/{year}/itens/human_itens_{PROVA}_{int(co_prova)}_{year}.csv\")\n",
    "\n",
    "        #df = generate_human_histogram_df(enem_human_df, PROVA=exam, CO_PROVA=co_prova, o='correct_percentage', normalize=True)\n",
    "        #df.to_csv(f\"C:/Users/pedro/Downloads/TRI/test_responses_humans/2022/correct_percentage/correct_percentage_{exam}_{int(co_prova)}.csv\")\n",
    "\n",
    "print(\"FINISHED.\")     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46b4bc-31ad-47a5-ad7f-e0d5e0e1a223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
